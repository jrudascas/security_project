{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "import calendar\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_columns', None)  \n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge is not required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Rebuild missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = '/u01/user8/Documents/Riñas/RNMC/data_2019_11/df_riñas_rnmc.csv'\n",
    "df_input=pd.read_csv(data_location,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"Tipo de dato\":df_input.dtypes.values,\n",
    "              \"Celdas con valor '-'\":(df_input == '-').sum().values,\n",
    "              \"Celdas con valor ''\":(df_input == '').sum().values,\n",
    "              \"Celdas con valor ' '\":(df_input == ' ').sum().values,\n",
    "              \"Celdas vacías\": df_input.isna().sum().values},\n",
    "             index=df_input.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-in methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Subdata(df,variables_array):\n",
    "    subdata=pd.DataFrame(df.groupby(variables_array).size(),columns=[\"Frecuencia\"]).sort_index().reset_index()\n",
    "    return subdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inp_dist(df,columna,vacio='-'):\n",
    "    df[columna].replace(vacio,np.NAN,inplace=True)\n",
    "    index_na=df[df[columna].isna()].index\n",
    "    valores=df[columna].dropna().value_counts().reset_index().values\n",
    "    df[columna].values[index_na]=np.random.choice(valores[:,0],p=(valores[:,1]/valores[:,1].sum()).astype(float),size=len(index_na))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define variables to rebuild"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured location fields: COD_UPZ, NOMBRE_UPZ, COD_SCAT, NOMBRE_SECTOR_CAT, COD_BARRIO, NOMBRE_BARRIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. A missing structured location field can be rebuild using the information of other structured field? \n",
    "#### No, since all missing structured location fields belong to the same registers subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_input.loc[df_input['COD_UPZ'] == '-']\n",
    "df2 = df_input.loc[df_input['NOMBRE_UPZ'] == '-']\n",
    "df3 = df_input.loc[df_input['COD_SCAT'] == '-']\n",
    "df4 = df_input.loc[df_input['NOMBRE_SECTOR_CAT'] == '-']\n",
    "df5 = df_input.loc[df_input['COD_BARRIO'] == '-']\n",
    "df6 = df_input.loc[df_input['NOMBRE_BARRIO'] == '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.equals(df2) and df1.equals(df3) and df1.equals(df4) and df1.equals(df5) and df1.equals(df6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. A missing structured location field can be rebuild using the latitude and longitude fields?\n",
    "#### No, these registers have latitude and longitude fields set on 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['LATITUD'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['LONGITUD'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. A missing structured location field can be rebuild other non-structured fields such as (TIPO_SITIO, STR_RELATO_HECHOS, DESCRIPCION_COMPORTAMIENTO)?\n",
    "#### No, non-structured fields dont have address or location information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['TIPO_SITIO'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "df1['STR_RELATO_HECHOS'].unique()\n",
    "address_regex= '(CL|CALLE|DG|DIAG|KR|CR|CRA|TV|TRANS)+\\s\\d+.*(,,)'\n",
    "list_address = []\n",
    "for relato in df1['STR_RELATO_HECHOS'].unique():\n",
    "    address_found = re.search(address_regex,relato)\n",
    "    list_address.append(address_found)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique elements on list_address\n",
    "mylist = list(set(list_address))\n",
    "mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['DESCRIPCION_COMPORTAMIENTO'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: structured location missing fields (COD_UPZ, NOMBRE_UPZ, COD_SCAT, NOMBRE_SECTOR_CAT, COD_BARRIO, NOMBRE_BARRIO) cant be rebuilt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign \"ND\" (No disponible) to structured location missing fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = df_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.loc[df_output['COD_UPZ']=='-','COD_UPZ'] = 'ND'\n",
    "df_output.loc[df_output['NOMBRE_UPZ']=='-','NOMBRE_UPZ'] = 'ND'\n",
    "df_output.loc[df_output['COD_SCAT']=='-','COD_SCAT'] = 'ND'\n",
    "df_output.loc[df_output['NOMBRE_SECTOR_CAT']=='-','NOMBRE_SECTOR_CAT'] = 'ND'\n",
    "df_output.loc[df_output['COD_BARRIO']=='-','COD_BARRIO'] = 'ND'\n",
    "df_output.loc[df_output['NOMBRE_BARRIO']=='-','NOMBRE_BARRIO'] = 'ND'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ====================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANGO_EDAD_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. RANGO_EDAD_1 can be rebuilt through other field?\n",
    "#### No, other fields dont have info related to offender age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df_output.loc[df_output['RANGO_EDAD_1'] == '-']\n",
    "df7.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Rebuild considering the variable distribution on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdata = create_Subdata(df_output,[\"RANGO_EDAD_1\"])\n",
    "subdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columna = 'RANGO_EDAD_1'\n",
    "inp_dist(df_output,columna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdata = create_Subdata(df_output,[\"RANGO_EDAD_1\"])\n",
    "subdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ======================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MEDIDA_CORRECTIVA_CODIGO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Field can be rebuilt through other registars that have the same título, artículo... cod_comportamiento?\n",
    "#### No, other registers dont share the same values for these fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = df_output.loc[df_output['MEDIDA_CORRECTIVA_CODIGO'] == '-']\n",
    "df8.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df8['TITULO'].unique())\n",
    "print(df8['CAPITULO'].unique())\n",
    "print(df8['ARTICULO'].unique())\n",
    "print(df8['DESCRIPCION_ARTICULO'].unique())\n",
    "print(df8['COD_COMPORTAMIENTO'].unique())\n",
    "print(df8['DESCRIPCION_COMPORTAMIENTO'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = df8[(df8['TITULO'] == 'Titulo 3') & (df8['CAPITULO'] == 'Capitulo 1') & (df8['ARTICULO'] == 27) & (df8['DESCRIPCION_ARTICULO'] == 'Comportamientos que ponen en riesgo la vida e integridad. Corregido por el art. 1, Decreto 555 de 2017. Los siguientes comportamientos ponen en riesgo la vida e integridad de las personas, y, por lo tanto, son contrarios a la convivencia:') & (df8['COD_COMPORTAMIENTO'] == 'Articulo 27') & (df8['DESCRIPCION_COMPORTAMIENTO'] == 'Comportamientos que ponen en riesgo la vida e integridad. Corregido por el art. 1, Decreto 555 de 2017. Los siguientes comportamientos ponen en riesgo la vida e integridad de las personas, y, por lo tanto, son contrarios a la convivencia:')]\n",
    "df9['MEDIDA_CORRECTIVA_CODIGO'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Rebuild considering the variable distribution on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdata = create_Subdata(df_output,[\"MEDIDA_CORRECTIVA_CODIGO\"])\n",
    "subdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columna = 'MEDIDA_CORRECTIVA_CODIGO'\n",
    "inp_dist(df_output,columna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdata = create_Subdata(df_output,[\"MEDIDA_CORRECTIVA_CODIGO\"])\n",
    "subdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ======================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STR_RELATO_HECHOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Variable can be rebuild through other fields?\n",
    "#### No. Strategy: 'ND' (No disponible) assigned to empty field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.loc[df_output['STR_RELATO_HECHOS'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.at[12566,'STR_RELATO_HECHOS'] = \"ND\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ======================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACTIVIDAD_COMERCIAL, RAZON_SOCIAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Variables can be rebuild through other registers with the same 'tipo_sitio' value?\n",
    "#### No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = df_output.loc[df_output[\"ACTIVIDAD_COMERCIAL\"] == '-']\n",
    "df10 = df_output.loc[df_output[\"RAZON_SOCIAL\"] == '-']\n",
    "df9.equals(df10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_output['TIPO_SITIO'].unique())\n",
    "print(df9['TIPO_SITIO'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = df_output.loc[df_output[\"ACTIVIDAD_COMERCIAL\"] != '-']\n",
    "print(len(df11))\n",
    "df11.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Assign 'ND' (No disponible) to variables with '-' value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.loc[df_output['ACTIVIDAD_COMERCIAL']=='-','ACTIVIDAD_COMERCIAL'] = 'ND'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.loc[df_output['RAZON_SOCIAL']=='-','RAZON_SOCIAL'] = 'ND'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check final status of variables after rebuild process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"Tipo de dato\":df_output.dtypes.values,\n",
    "              \"Celdas con valor '-'\":(df_output == '-').sum().values,\n",
    "              \"Celdas con valor 'ND'\":(df_output == 'ND').sum().values,\n",
    "              \"Celdas vacías\": df_output.isna().sum().values},\n",
    "             index=df_output.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.to_csv(r'/u01/user8/Documents/Riñas/RNMC/data_2019_11/rebuild_rnmc_05022020.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Standardise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = '/u01/user8/Documents/Riñas/RNMC/data_2019_11/rebuild_rnmc_05022020.csv'\n",
    "df_input = pd.read_csv(data_location,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"Tipo de dato\":df_input.dtypes.values,\n",
    "              \"Celdas con valor '-'\":(df_input == '-').sum().values,\n",
    "              \"Celdas con valor 'ND'\":(df_input == 'ND').sum().values,\n",
    "              \"Celdas vacías\": df_input.isna().sum().values},\n",
    "             index=df_input.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Unique register by riña event: since NUM_ID_HECHOS is a unique identifier is expected df size match with  number of unique NUM_ID_HECHOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_input))\n",
    "print(len(df_input['EXPEDIENTE'].unique()))\n",
    "print(len(df_input['COMPARENDO'].unique()))\n",
    "print(len(df_input['NUM_ID_HECHOS'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the duplicated NUM_ID_HECHOS\n",
    "df_id_hechos_duplicated = df_input[df_input.duplicated(['NUM_ID_HECHOS'])]\n",
    "list_id_hechos_duplicated = df_id_hechos_duplicated['NUM_ID_HECHOS'].tolist()\n",
    "list_id_hechos_duplicated[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Difference among duplicated pairs NUM_ID_HECHOS seems to be RANGO_EDAD variable\n",
    "df_input.loc[df_input['NUM_ID_HECHOS']==list_id_hechos_duplicated[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeated NUM_ID_HECHOS are related with RANGO_EDAD missing registers that were rebuilt? No\n",
    "df7.loc[df7['NUM_ID_HECHOS']==list_id_hechos_duplicated[123]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check duplicated pairs id_hechos just differ on RANGO_EDAD\n",
    "list_differ_not_age = []\n",
    "for id_num in list_id_hechos_duplicated:\n",
    "    df = df_input.loc[df_input['NUM_ID_HECHOS']==id_num]\n",
    "    df_duplicated = df[df.duplicated(['EXPEDIENTE','COMPARENDO','FECHA','HORA','ANIO','MES','LATITUD','LONGITUD','COD_LOCALIDAD','NOMBRE_LOCALIDAD','COD_UPZ','NOMBRE_UPZ','COD_SCAT','NOMBRE_SECTOR_CAT','COD_BARRIO','NOMBRE_BARRIO','TIPO_SITIO','TITULO','CAPITULO','ARTICULO','DESCRIPCION_ARTICULO','COD_COMPORTAMIENTO','DESCRIPCION_COMPORTAMIENTO','TIPO_PRIORIZACION','MEDIDA_CORRECTIVA_CODIGO','ES_PEDAGOGICO','STR_RELATO_HECHOS','ACTIVIDAD_COMERCIAL','RAZON_SOCIAL','NUM_ID_HECHOS'])]\n",
    "    if len(df_duplicated) == 0:\n",
    "        list_differ_not_age.append(id_num)\n",
    "len(list_differ_not_age)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_differ_not_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_input.loc[df_input['NUM_ID_HECHOS'] == 1993080]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_input))\n",
    "print(len(df_id_hechos_duplicated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_input.drop_duplicates(subset='NUM_ID_HECHOS', keep='first')\n",
    "print(len(df_clean) == len(df_input['NUM_ID_HECHOS'].unique()))\n",
    "print((df_clean['NUM_ID_HECHOS'].unique() == df_input['NUM_ID_HECHOS'].unique()).all())\n",
    "df_clean[df_clean.duplicated(['NUM_ID_HECHOS'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = df_clean\n",
    "df_output.to_csv(r'/u01/user8/Documents/Riñas/RNMC/data_2019_11/standardise_by_num_id_hechos_rnmc_06022020.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 One register per event: event that occurs within 400 mts radius and 20 minutes time interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = '/u01/user8/Documents/Riñas/RNMC/data_2019_11/standardise_by_num_id_hechos_rnmc_06022020.csv'\n",
    "df_input = pd.read_csv(data_location,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create timpestamp col to handle time ranges on unique event process\n",
    "df_input['time_stamp']=pd.to_datetime(df_input['FECHA'] + ' ' + df_input[\"HORA\"].astype(str).str.rjust(4,'0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find duplicated events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, datetime\n",
    "time_offset = 20\n",
    "coor_offset = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicated_events(df, row):\n",
    "    current_time = row['time_stamp']\n",
    "    current_lat = row['LATITUD']\n",
    "    current_lon = row['LONGITUD']\n",
    "    current_point=Point(current_lon,current_lat)\n",
    "\n",
    "    duplicated_event_idx = {}\n",
    "    limit_time_interval = current_time + datetime.timedelta(minutes = time_offset)\n",
    "    df_event_time = df.loc[(df['time_stamp'] >= current_time) & (df['time_stamp'] < limit_time_interval)]\n",
    "    \n",
    "    lat_point_list = [current_lat-coor_offset, current_lat-coor_offset, current_lat+coor_offset, current_lat+coor_offset]\n",
    "    lon_point_list = [current_lon+coor_offset, current_lon-coor_offset, current_lon-coor_offset, current_lon+coor_offset]\n",
    "    polygon_event = Polygon(zip(lon_point_list, lat_point_list))\n",
    "    \n",
    "    for index, row in df_event_time.iterrows():\n",
    "        point=Point(row['LONGITUD'],row['LATITUD'])\n",
    "        if point.within(polygon_event):\n",
    "            #duplicated_event_idx.append(index)\n",
    "            duplicated_event_idx[index] = row['NUM_ID_HECHOS']\n",
    "    return duplicated_event_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = df_input.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output['dup_event'] = df_output.apply (lambda row: find_duplicated_events(df_output, row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.to_csv('/u01/user8/Documents/Riñas/RNMC/data_2019_11/standardise_find_dup_spatio_temporal_events_rnmc_06022020.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete duplicated events: preserve the first event on dup_event column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = '/u01/user8/Documents/Riñas/RNMC/data_2019_11/standardise_find_dup_spatio_temporal_events_rnmc_06022020.csv'\n",
    "df_input = pd.read_csv(data_location,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"Tipo de dato\":df_input.dtypes.values,\n",
    "              \"Celdas con valor '-'\":(df_input == '-').sum().values,\n",
    "              \"Celdas con valor 'ND'\":(df_input == 'ND').sum().values,\n",
    "              \"Celdas vacías\": df_input.isna().sum().values},\n",
    "             index=df_input.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_input.iloc[[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input.iloc[[8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get index of registers that should be deleted\n",
    "import ast\n",
    "df = df_input\n",
    "list_idx_repeated = []\n",
    "list_idx_preserved = []\n",
    "registers_to_process = len(df)\n",
    "list_idx_processed =[]\n",
    "counter_processed = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    dup_event_x = ast.literal_eval(df.at[index,'dup_event'])\n",
    "    current_dup_events = list(dup_event_x.keys())\n",
    "\n",
    "    if (current_dup_events[0] not in list_idx_processed) & (current_dup_events[0] not in list_idx_preserved):\n",
    "        list_idx_preserved.append(current_dup_events[0])\n",
    "        list_idx_processed.append(current_dup_events[0])\n",
    "        current_dup_events.pop(0)\n",
    "\n",
    "    for idx_event in current_dup_events:\n",
    "        if idx_event not in list_idx_processed:\n",
    "            list_idx_repeated.append(idx_event)\n",
    "            list_idx_processed.append(idx_event)\n",
    "                \n",
    "    counter_processed += 1\n",
    "    \n",
    "    print('Registers processed: ',counter_processed,'/',registers_to_process)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check (quantitatively) ID of preserved and repeated events index was succesful\n",
    "print(len(list_idx_repeated)+len(list_idx_preserved))\n",
    "print(len(list_idx_processed))\n",
    "join_list = list_idx_preserved + list_idx_repeated\n",
    "\n",
    "import collections\n",
    "seen = set()\n",
    "uniq = []\n",
    "for x in join_list:\n",
    "    if x not in seen:\n",
    "        uniq.append(x)\n",
    "        seen.add(x)\n",
    "\n",
    "print(len(uniq))\n",
    "\n",
    "lst = join_list\n",
    "dupItems = []\n",
    "uniqItems = {}\n",
    "for x in lst:\n",
    "    if x not in uniqItems:\n",
    "        uniqItems[x] = 1\n",
    "    else:\n",
    "        if uniqItems[x] == 1:\n",
    "            dupItems.append(x)\n",
    "        uniqItems[x] += 1\n",
    "        \n",
    "print(len(dupItems))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = df_input.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output=df_output.drop(list_idx_repeated)\n",
    "df_output.drop(columns=['dup_event','time_stamp'],inplace=True)\n",
    "df_output.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save lists\n",
    "MyFile=open('/u01/user8/Documents/Riñas/RNMC/data_2019_11/standardise_dup_events_list_idx_preserved_06022020.txt','w')\n",
    "MyList=map(lambda x: str(x)+'\\n', list_idx_preserved)\n",
    "MyFile.writelines(MyList)\n",
    "MyFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save lists\n",
    "MyFile=open('/u01/user8/Documents/Riñas/RNMC/data_2019_11/standardise_dup_events_list_idx_repeated_06022020.txt','w')\n",
    "MyList=map(lambda x: str(x)+'\\n', list_idx_repeated)\n",
    "MyFile.writelines(MyList)\n",
    "MyFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"Tipo de dato\":df_output.dtypes.values,\n",
    "              \"Celdas con valor '-'\":(df_output == '-').sum().values,\n",
    "              \"Celdas con valor 'ND'\":(df_output == 'ND').sum().values,\n",
    "              \"Celdas vacías\": df_output.isna().sum().values},\n",
    "             index=df_output.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.to_csv(r'/u01/user8/Documents/Riñas/RNMC/data_2019_11/standardise_result_rnmc_06022020.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = '/home/combios/Documents/amreyesp/clean_rnmc_data/standardise_result_rnmc_06022020.csv'\n",
    "df_input = pd.read_csv(data_location,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(df_input.shape)\n",
    "pd.DataFrame({\"Tipo de dato\":df_input.dtypes.values,\n",
    "              \"Celdas con valor '-'\":(df_input == '-').sum().values,\n",
    "              \"Celdas con valor 'ND'\":(df_input == 'ND').sum().values,\n",
    "              \"Celdas vacías\": df_input.isna().sum().values},\n",
    "             index=df_input.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify FECHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It´s a REGEX with the form: YYYY-mm-dd\n",
    "regex_fecha = '^\\d{4}-\\d{2}-\\d{2}$'\n",
    "df_input['FECHA'].str.contains(regex_fecha, regex=True).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify HORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It´s a number between 0 and 2359\n",
    "print(df_input['HORA'].between(0,2359).all())\n",
    "\n",
    "# It´s a regex:\n",
    "regex_hora = '^[0-2][0-9][0-5]|[0-9]$'\n",
    "df_input['HORA'].apply(str).str.contains(regex_hora, regex=True).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify ANIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It´s a number between 2017 and 2019\n",
    "df_input['ANIO'].between(2017,2019).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify MES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It´s a number between 1 and 12\n",
    "df_input['MES'].between(1,12).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify COD_LOCALIDAD - NOMBRE_LOCALIDAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_aux = 'NUM_ID_HECHOS'\n",
    "df_input.groupby(['COD_LOCALIDAD','NOMBRE_LOCALIDAD']).agg({var_aux:'count'}).reset_index().rename(columns={var_aux:'Frecuencia'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = df_input.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.loc[df_output['NOMBRE_LOCALIDAD'] == 'ANTONIO NARI?O', 'NOMBRE_LOCALIDAD'] = \"ANTONIO NARIÑO\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify LATITUD, LONGITUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be in Bogotá\n",
    "json_file=\"/home/combios/Documents/amreyesp/security_project/assets/bogota_polygon.geojson\"\n",
    "bog_loc=gpd.read_file(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bog_location(df, row):\n",
    "    lat = row['LATITUD']\n",
    "    lon = row['LONGITUD']\n",
    "    current_point = Point(lon,lat)\n",
    "    if bog_loc.geometry.contains(current_point)[0]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output['in_bogota?'] = df_output.apply (lambda row: check_bog_location(df_output, row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_output))\n",
    "print(len(df_output.loc[df_output['in_bogota?'] == True]))\n",
    "print(len(df_output.loc[df_output['in_bogota?'] == False]))\n",
    "print(len(df_output.loc[(df_output['in_bogota?'] == False) & (df_output['LATITUD']==-1) & (df_output['LONGITUD']==-1)]))\n",
    "print(len(df_output.loc[(df_output['in_bogota?'] == False) & (df_output['LATITUD']!=-1) & (df_output['LONGITUD']!=-1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.loc[(df_output['in_bogota?'] == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.to_csv(r'/home/combios/Documents/amreyesp/clean_rnmc_data/normalise_find_out_bogota_RNMC_12022020.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get index of registers out of Bogota and drop it\n",
    "list_index_out_bogota=df_output[(df_output['in_bogota?'] == False)].index\n",
    "df_output=df_output.drop(list_index_out_bogota)\n",
    "df_output['in_bogota?'].all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.drop(columns=['index','in_bogota?'],inplace=True)\n",
    "df_output.reset_index(inplace=True)\n",
    "df_output.drop(columns=['index'],inplace=True)\n",
    "print(len(df_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### other variables: TIPO_SITIO, RANGO_EDAD_1, TIPO_PRIORIZACION, ES_PEDAGOGICO, STR_RELATO_HECHOS, ACTIVIDAD_COMERCIAL, RAZON_SOCIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output['TIPO_SITIO'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output['RANGO_EDAD_1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output['TIPO_PRIORIZACION'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output['ES_PEDAGOGICO'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output['STR_RELATO_HECHOS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output['ACTIVIDAD_COMERCIAL'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output['RAZON_SOCIAL'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normativity variables: TITULO, CAPITULO, ARTICULO, DESCRIPCION_ARTICULO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output['TITULO'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output['CAPITULO'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output['ARTICULO'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output['DESCRIPCION_ARTICULO'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output['COD_COMPORTAMIENTO'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output['DESCRIPCION_COMPORTAMIENTO'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output['MEDIDA_CORRECTIVA_CODIGO'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.to_csv(r'/home/combios/Documents/amreyesp/clean_rnmc_data/normalise_result_rnmc_12022020.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. De-duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = '/home/combios/Documents/amreyesp/clean_rnmc_data/normalise_result_rnmc_12022020.csv'\n",
    "df_input = pd.read_csv(data_location,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_input.shape)\n",
    "pd.DataFrame({\"Tipo de dato\":df_input.dtypes.values,\n",
    "              \"Celdas con valor '-'\":(df_input == '-').sum().values,\n",
    "              \"Celdas con valor 'ND'\":(df_input == 'ND').sum().values,\n",
    "              \"Celdas vacías\": df_input.isna().sum().values},\n",
    "             index=df_input.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify there are not identycal rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Filas duplicadas\",df_input.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify unique NUM_ID_HECHOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_input) == len(df_input['NUM_ID_HECHOS'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input.to_csv(r'/home/combios/Documents/amreyesp/clean_rnmc_data/deduplicate_rnmc_12022020.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Verify and enrich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = '/home/combios/Documents/amreyesp/clean_rnmc_data/deduplicate_rnmc_12022020.csv'\n",
    "df_input = pd.read_csv(data_location,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_input.shape)\n",
    "pd.DataFrame({\"Tipo de dato\":df_input.dtypes.values,\n",
    "              \"Celdas con valor '-'\":(df_input == '-').sum().values,\n",
    "              \"Celdas con valor 'ND'\":(df_input == 'ND').sum().values,\n",
    "              \"Celdas vacías\": df_input.isna().sum().values},\n",
    "             index=df_input.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output=df_input.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify columns with empty or anomalous values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check ACTIVIDAD_COMERCIAL, RAZON_SOCIAL  with 'ND' values\n",
    "df1 = df_output.loc[df_output['ACTIVIDAD_COMERCIAL']=='ND']\n",
    "df2 = df_output.loc[df_output['RAZON_SOCIAL']=='ND']\n",
    "df1.equals(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete aditional columns created on cleaning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare columns of original dataset vs cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv('/home/combios/Documents/amreyesp/clean_rnmc_data/df_riñas_rnmc.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_original.columns == df_output.columns).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_output.shape)\n",
    "pd.DataFrame({\"Tipo de dato\":df_output.dtypes.values,\n",
    "              \"Celdas con valor '-'\":(df_output == '-').sum().values,\n",
    "              \"Celdas con valor 'ND'\":(df_output == 'ND').sum().values,\n",
    "              \"Celdas vacías\": df_output.isna().sum().values},\n",
    "             index=df_output.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.to_csv(r'/home/combios/Documents/amreyesp/clean_rnmc_data/verify_enrich_rnmc_12022020.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
