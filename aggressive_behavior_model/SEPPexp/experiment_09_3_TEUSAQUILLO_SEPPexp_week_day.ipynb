{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "- Make prediction for localidad level (Teusaquillo) using experimental design 2, Naive Counting and SEPPexp based on week-days model.\n",
    "- Compare model performance using hit rate traditional implementation, true positives proportion and PAI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis:\n",
    "SEPP exp prediction based on week-days performance is better than the obtained with counting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to import `rtree`.\n",
      "Failed to import `rtree`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from services.prediction_experiment import PredictionExperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services import prediction_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hit_rate_from_dict(row,column,coverage):\n",
    "    return row[column][coverage]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIEDCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '/Users/anamaria/Desktop/dev/security_project/datasets/deduplicate_siedco_09062020.csv'\n",
    "siedco_info = {'name':'SIEDCO','path':csv_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dates = {'initial':'2018-03-01','final':'2018-09-30'}\n",
    "validation_dates = {'initial':'2018-10-01','final':'2018-10-07'}\n",
    "metrics = ''\n",
    "aggregation = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anamaria/Desktop/dev/security_project/security_venv/lib/python3.7/site-packages/ipykernel_launcher.py:4: DtypeWarning: Columns (32,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_subset_dates {'initial': datetime.datetime(2018, 3, 1, 0, 0), 'final': datetime.datetime(2018, 9, 30, 0, 0)}\n",
      "current_validation_date 2018-10-01 00:00:00\n",
      "381\n",
      "train_subset_dates {'initial': datetime.datetime(2018, 3, 1, 0, 0), 'final': datetime.datetime(2018, 10, 1, 0, 0)}\n",
      "current_validation_date 2018-10-02 00:00:00\n",
      "381\n",
      "train_subset_dates {'initial': datetime.datetime(2018, 3, 1, 0, 0), 'final': datetime.datetime(2018, 10, 2, 0, 0)}\n",
      "current_validation_date 2018-10-03 00:00:00\n",
      "384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../services/process_data.py:77: UserWarning: Empty filter result, check dates. Initial date: 2018-10-01, final date: 2018-10-02\n",
      "  warnings.warn('Empty filter result, check dates. Initial date: '+initial_date.strftime('%Y-%m-%d')+', final date: '+real_final_date.strftime('%Y-%m-%d'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_subset_dates {'initial': datetime.datetime(2018, 3, 1, 0, 0), 'final': datetime.datetime(2018, 10, 3, 0, 0)}\n",
      "current_validation_date 2018-10-04 00:00:00\n",
      "385\n",
      "train_subset_dates {'initial': datetime.datetime(2018, 3, 1, 0, 0), 'final': datetime.datetime(2018, 10, 4, 0, 0)}\n",
      "current_validation_date 2018-10-05 00:00:00\n",
      "385\n",
      "train_subset_dates {'initial': datetime.datetime(2018, 3, 1, 0, 0), 'final': datetime.datetime(2018, 10, 5, 0, 0)}\n",
      "current_validation_date 2018-10-06 00:00:00\n",
      "387\n",
      "train_subset_dates {'initial': datetime.datetime(2018, 3, 1, 0, 0), 'final': datetime.datetime(2018, 10, 6, 0, 0)}\n",
      "current_validation_date 2018-10-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../services/process_data.py:77: UserWarning: Empty filter result, check dates. Initial date: 2018-10-04, final date: 2018-10-05\n",
      "  warnings.warn('Empty filter result, check dates. Initial date: '+initial_date.strftime('%Y-%m-%d')+', final date: '+real_final_date.strftime('%Y-%m-%d'))\n",
      "../services/process_data.py:77: UserWarning: Empty filter result, check dates. Initial date: 2018-10-06, final date: 2018-10-07\n",
      "  warnings.warn('Empty filter result, check dates. Initial date: '+initial_date.strftime('%Y-%m-%d')+', final date: '+real_final_date.strftime('%Y-%m-%d'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387\n"
     ]
    }
   ],
   "source": [
    "filter_localidad = {'field':'LOCALIDAD','value':'TEUSAQUILLO'}\n",
    "model = \"NaiveCounting\"\n",
    "localidad_experiment = PredictionExperiment(dataset_info=siedco_info, custom_filter=filter_localidad,train_dates=train_dates, validation_dates=validation_dates, model=model,metrics='',aggregation_data='')\n",
    "prediction_array = localidad_experiment.run_ncv_experiment(time_unit='',grid_size=150, outer_iterations='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counting = pd.DataFrame(prediction_array, columns =['initial-date','final-date','prediction','eval_pts'])\n",
    "df_result = df_counting.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverages = [2,4,6,8,10,12,14,16,18,20]\n",
    "df_result['hitrate_default'] = df_result.apply(lambda row: prediction_metrics.measure_hit_rates(row['prediction'],row['eval_pts'],coverages,'default'), axis=1)\n",
    "df_result['hitrate_TP'] = df_result.apply(lambda row: prediction_metrics.measure_hit_rates(row['prediction'],row['eval_pts'],coverages,'ground_truth_coverage'), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##For hitrate_TP \"true positives\"\n",
    "df_result['coverage_TP'] = df_result.apply(lambda row: list(row['hitrate_TP'].keys())[0], axis=1)\n",
    "df_result['hit_rate_TP'] = df_result.apply(lambda row: list(row['hitrate_TP'].values())[0], axis=1)\n",
    "df_result['PAI_TP'] = df_result['hit_rate_TP'] / (df_result['coverage_TP']/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##For hitrate_default\n",
    "coverages = [2.0,4.0,6.0,8.0,10.0,12.0,14.0,16.0,18.0,20.0]\n",
    "column_dict = 'hitrate_default'\n",
    "for c in coverages:\n",
    "    new_hit_rate_column = 'hit_rate_default_coverage_'+str(c)\n",
    "    df_result[new_hit_rate_column] = df_result.apply(lambda row: get_hit_rate_from_dict(row,column_dict,c), axis=1)\n",
    "\n",
    "    ##PAI\n",
    "    new_column = 'PAI_default_coverage_'+str(c)\n",
    "    df_result[new_column] = df_result[new_hit_rate_column]/(c/100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coverage_TP                        0.126126\n",
      "hit_rate_TP                        0.000000\n",
      "PAI_TP                             0.000000\n",
      "hit_rate_default_coverage_2.0      0.200000\n",
      "PAI_default_coverage_2.0          10.000000\n",
      "hit_rate_default_coverage_4.0      0.200000\n",
      "PAI_default_coverage_4.0           5.000000\n",
      "hit_rate_default_coverage_6.0      0.200000\n",
      "PAI_default_coverage_6.0           3.333333\n",
      "hit_rate_default_coverage_8.0      0.200000\n",
      "PAI_default_coverage_8.0           2.500000\n",
      "hit_rate_default_coverage_10.0     0.200000\n",
      "PAI_default_coverage_10.0          2.000000\n",
      "hit_rate_default_coverage_12.0     0.200000\n",
      "PAI_default_coverage_12.0          1.666667\n",
      "hit_rate_default_coverage_14.0     0.200000\n",
      "PAI_default_coverage_14.0          1.428571\n",
      "hit_rate_default_coverage_16.0     0.266667\n",
      "PAI_default_coverage_16.0          1.666667\n",
      "hit_rate_default_coverage_18.0     0.266667\n",
      "PAI_default_coverage_18.0          1.481481\n",
      "hit_rate_default_coverage_20.0     0.266667\n",
      "PAI_default_coverage_20.0          1.333333\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#delete datetimes where no crimes were reported (0 crimes on ground truth -> hit-rate = -1)\n",
    "df_result = df_result[df_result['hit_rate_default_coverage_2.0']!= -1]\n",
    "print(df_result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEPPexp week-day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dates = {'initial':'2014-03-01','final':'2018-09-30'}\n",
    "validation_dates = {'initial':'2018-10-01','final':'2018-10-07'}\n",
    "metrics = ''\n",
    "aggregation = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anamaria/Desktop/dev/security_project/security_venv/lib/python3.7/site-packages/ipykernel_launcher.py:4: DtypeWarning: Columns (32,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_subset_dates {'initial': datetime.datetime(2014, 3, 1, 0, 0), 'final': datetime.datetime(2018, 9, 30, 0, 0)}\n",
      "current_validation_date 2018-10-01 00:00:00\n",
      "omega: 0.0045822012274454775, theta: 0.00784789580478372\n",
      "244\n",
      "train_subset_dates {'initial': datetime.datetime(2014, 3, 1, 0, 0), 'final': datetime.datetime(2018, 10, 1, 0, 0)}\n",
      "current_validation_date 2018-10-02 00:00:00\n",
      "omega: 0.012158618230911966, theta: 0.007872317244487882\n",
      "246\n",
      "train_subset_dates {'initial': datetime.datetime(2014, 3, 1, 0, 0), 'final': datetime.datetime(2018, 10, 2, 0, 0)}\n",
      "current_validation_date 2018-10-03 00:00:00\n",
      "omega: 0.017537528770544375, theta: 0.011210216601137593\n",
      "259\n",
      "train_subset_dates {'initial': datetime.datetime(2014, 3, 1, 0, 0), 'final': datetime.datetime(2018, 10, 3, 0, 0)}\n",
      "current_validation_date 2018-10-04 00:00:00\n",
      "omega: 0.047654581722577305, theta: 0.011914034597373611\n",
      "252\n",
      "train_subset_dates {'initial': datetime.datetime(2014, 3, 1, 0, 0), 'final': datetime.datetime(2018, 10, 4, 0, 0)}\n",
      "current_validation_date 2018-10-05 00:00:00\n",
      "omega: 0.0026890337916544243, theta: 0.017689072040775265\n",
      "280\n",
      "train_subset_dates {'initial': datetime.datetime(2014, 3, 1, 0, 0), 'final': datetime.datetime(2018, 10, 5, 0, 0)}\n",
      "current_validation_date 2018-10-06 00:00:00\n",
      "omega: 3.359580587080074e-05, theta: 2.1489105805098514e-14\n",
      "309\n",
      "train_subset_dates {'initial': datetime.datetime(2014, 3, 1, 0, 0), 'final': datetime.datetime(2018, 10, 6, 0, 0)}\n",
      "current_validation_date 2018-10-07 00:00:00\n",
      "omega: 0.003231895765861611, theta: 0.011546383209634822\n",
      "313\n"
     ]
    }
   ],
   "source": [
    "filter_localidad = {'field':'LOCALIDAD','value':'TEUSAQUILLO'}\n",
    "model = \"SEPPexpWeekDay\"\n",
    "localidad_experiment = PredictionExperiment(dataset_info=siedco_info, custom_filter=filter_localidad,train_dates=train_dates, validation_dates=validation_dates, model=model,metrics='',aggregation_data='')\n",
    "prediction_array = localidad_experiment.run_ncv_experiment(time_unit='',grid_size=150, outer_iterations='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seppexp = pd.DataFrame(prediction_array, columns =['initial-date','final-date','prediction','eval_pts'])\n",
    "df_result = df_seppexp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverages = [2,4,6,8,10,12,14,16,18,20]\n",
    "df_result['hitrate_default'] = df_result.apply(lambda row: prediction_metrics.measure_hit_rates(row['prediction'],row['eval_pts'],coverages,'default'), axis=1)\n",
    "df_result['hitrate_TP'] = df_result.apply(lambda row: prediction_metrics.measure_hit_rates(row['prediction'],row['eval_pts'],coverages,'ground_truth_coverage'), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##For hitrate_TP \"true positives\"\n",
    "df_result['coverage_TP'] = df_result.apply(lambda row: list(row['hitrate_TP'].keys())[0], axis=1)\n",
    "df_result['hit_rate_TP'] = df_result.apply(lambda row: list(row['hitrate_TP'].values())[0], axis=1)\n",
    "df_result['PAI_TP'] = df_result['hit_rate_TP'] / (df_result['coverage_TP']/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##For hitrate_default\n",
    "coverages = [2.0,4.0,6.0,8.0,10.0,12.0,14.0,16.0,18.0,20.0]\n",
    "column_dict = 'hitrate_default'\n",
    "for c in coverages:\n",
    "    new_hit_rate_column = 'hit_rate_default_coverage_'+str(c)\n",
    "    df_result[new_hit_rate_column] = df_result.apply(lambda row: get_hit_rate_from_dict(row,column_dict,c), axis=1)\n",
    "\n",
    "    ##PAI\n",
    "    new_column = 'PAI_default_coverage_'+str(c)\n",
    "    df_result[new_column] = df_result[new_hit_rate_column]/(c/100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coverage_TP                       0.128566\n",
      "hit_rate_TP                       0.000000\n",
      "PAI_TP                            0.000000\n",
      "hit_rate_default_coverage_2.0     0.133333\n",
      "PAI_default_coverage_2.0          6.666667\n",
      "hit_rate_default_coverage_4.0     0.133333\n",
      "PAI_default_coverage_4.0          3.333333\n",
      "hit_rate_default_coverage_6.0     0.133333\n",
      "PAI_default_coverage_6.0          2.222222\n",
      "hit_rate_default_coverage_8.0     0.133333\n",
      "PAI_default_coverage_8.0          1.666667\n",
      "hit_rate_default_coverage_10.0    0.133333\n",
      "PAI_default_coverage_10.0         1.333333\n",
      "hit_rate_default_coverage_12.0    0.400000\n",
      "PAI_default_coverage_12.0         3.333333\n",
      "hit_rate_default_coverage_14.0    0.400000\n",
      "PAI_default_coverage_14.0         2.857143\n",
      "hit_rate_default_coverage_16.0    0.400000\n",
      "PAI_default_coverage_16.0         2.500000\n",
      "hit_rate_default_coverage_18.0    0.400000\n",
      "PAI_default_coverage_18.0         2.222222\n",
      "hit_rate_default_coverage_20.0    0.400000\n",
      "PAI_default_coverage_20.0         2.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#delete datetimes where no crimes were reported (0 crimes on ground truth -> hit-rate = -1)\n",
    "df_result = df_result[df_result['hit_rate_default_coverage_2.0']!= -1]\n",
    "print(df_result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
