{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment description\n",
    "## Hypothesis: \n",
    "Predictability values are similar considering different date intervals\n",
    "## Method: \n",
    "- Remove outliers\n",
    "- Measure predictability for 7 days timewindows and levelCrime=3 on intervals (months, bimesters, semesters)\n",
    "- Implement a metric to compare the difference among predictability values\n",
    "\n",
    "## Parameters: \n",
    "- Time windows: 7\n",
    "- Crime levels: 3\n",
    "- Aggregation: localidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-in methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import math\n",
    "from math import pi\n",
    "import geopandas as gpd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_initial_dataset_day(df_by_date,name_day):\n",
    "    df_by_date = df_by_date.reset_index()\n",
    "    df_by_date['day_of_week'] = df_by_date['date'].dt.day_name()\n",
    "    monday_idx = df_by_date.index[df_by_date['day_of_week'] == name_day].tolist()[0]\n",
    "    print('monday_idx',monday_idx)\n",
    "    df_by_date = df_by_date[monday_idx:].set_index('date').drop(['day_of_week'],axis=1)\n",
    "    return df_by_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods for time windows\n",
    "def im2patches(im,n):\n",
    "    patches = [];\n",
    "    for i in range(len(im)-n):\n",
    "        patch = im[i:(i+n-1)]        \n",
    "        patch = patch - np.nanmean(patch);\n",
    "        if(np.linalg.norm(patch)>0):\n",
    "            patch = patch/np.linalg.norm(patch);\n",
    "        if i==0:\n",
    "            patches = patch;\n",
    "        else:\n",
    "            patches = np.vstack((patches,patch))\n",
    "    return patches;\n",
    "\n",
    "def writeEmbeding(timeSeries,lenWindow,samplePath, scenarioName):\n",
    "    slicingWindows = im2patches(timeSeries,lenWindow);\n",
    "    workingPath = '/Users/anamaria/Desktop/dev/security_project/periodicity_experiments/predictability/slicing/'\n",
    "    prevStation = str(samplePath);\n",
    "    with open(workingPath+'slicingWindows'+\"_\"+str(prevStation)+\"_\"+str(scenarioName)+\"_\"+str(lenWindow)+'_.pickle', 'wb') as f:\n",
    "        lv = slicingWindows.tolist();                        \n",
    "        pickle.dump(lv, f, protocol=2)\n",
    "\n",
    "    workingPath = '/Users/anamaria/Desktop/dev/security_project/periodicity_experiments/predictability/timeSeries/'    \n",
    "    with open(workingPath+'timeSeries'+\"_\"+str(prevStation)+\"_\"+str(scenarioName)+\"_\"+str(lenWindow)+'_.pickle', 'wb') as f:\n",
    "        lv = timeSeries.tolist();                        \n",
    "        pickle.dump(lv, f, protocol=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Methods for predictability\n",
    "def getBarcode(samplePath,lenWindow,scenarioName):\n",
    "    workingPath = '/Users/anamaria/Desktop/dev/security_project/periodicity_experiments/predictability/'\n",
    "    barcode = [];\n",
    "\n",
    "    with open(workingPath+'timeSeries/'+'timeSeries_'+samplePath+\"_\"+str(scenarioName)+'_'+str(lenWindow)+'_'+'.pickle', 'rb') as f:\n",
    "            timeSeries = pickle.load(f);            \n",
    "    return (barcode,timeSeries);\n",
    "\n",
    "def computeBarcodeEntropy(barsLenB0):\n",
    "    barlen = np.array(barsLenB0);\n",
    "    barlen = barlen/barlen.sum();\n",
    "    hbc = 0;\n",
    "    for i in range(barlen.shape[0]):\n",
    "        if barlen[i]!=0:\n",
    "            hbc = hbc-(barlen[i])*np.log(barlen[i]);\n",
    "    return hbc;\n",
    "\n",
    "\n",
    "def computeGeneralPredictability(timeSeries,binsData,lenWindow):\n",
    "    # Colwell, R. K. (1974). Predictability, constancy, and contingency of periodic phenomena. Ecology, 55(5), 1148-1153.\n",
    "    # Normalize the caudal values\n",
    "    nLevels = binsData.shape[0]-1;\n",
    "    matStations = np.array(timeSeries).reshape((np.array(timeSeries).shape[0]//lenWindow,lenWindow))    \n",
    "\n",
    "    grandMean = np.mean(np.mean(matStations));\n",
    "    #matStations = matStations / grandMean;\n",
    "    N = np.zeros((nLevels,lenWindow));\n",
    "    for i in range(1,matStations.shape[1]): \n",
    "        # Computes histograms per columns\n",
    "        hist, bin_edges = np.histogram(matStations[:,i],bins = binsData);\n",
    "        N[:,i] = hist;\n",
    "    X = np.sum(N, axis=0);\n",
    "    Y = np.sum(N, axis=1);\n",
    "    Z = np.sum(Y);\n",
    "    hx = 0;\n",
    "    hy = 0;\n",
    "    hxy = 0;\n",
    "    for j in range(X.shape[0]):\n",
    "        if X[j]!=0:\n",
    "            hx = hx-(X[j]/Z)*np.log(X[j]/Z);\n",
    "            \n",
    "    for i in range(Y.shape[0]):\n",
    "        if Y[i]!=0:\n",
    "            hy = hy-(Y[i]/Z)*np.log(Y[i]/Z);\n",
    "            \n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(X.shape[0]):\n",
    "            if N[i,j]!=0:\n",
    "                hxy = hxy-((N[i,j]/Z)*np.log(N[i,j]/Z));    \n",
    "    \n",
    "    # predictability\n",
    "    p = 1 - (hxy - hx)/np.log(N.shape[0]);\n",
    "    # constancy\n",
    "    c = 1 - hy/np.log(N.shape[0]);\n",
    "    # Returns constancy and contingency\n",
    "    return (c,p-c,p);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df,min_date_period,max_date_period):\n",
    "    df=df.drop(columns=['PERIODO_TS','LOCALIDAD'])\n",
    "    #Remove outliers\n",
    "    q_hi = df[\"total_eventos\"].quantile(0.99)\n",
    "    df = df[(df[\"total_eventos\"] < q_hi)]\n",
    "    print('remove outliers')\n",
    "    print(df.head(3))\n",
    "\n",
    "    #Make sure dataset include consecutive dates in period\n",
    "    idx = pd.date_range(min_date_period, max_date_period)\n",
    "    df = df.reindex(idx, fill_value=int(df[\"total_eventos\"].mean()))\n",
    "    df = df.reset_index().rename(columns={'index': 'date'}).set_index('date')\n",
    "    print('set consecutive dates')\n",
    "    print(df.head(3))\n",
    "    \n",
    "    #Make sure dataset starts on Monday for the experiment\n",
    "    df = set_initial_dataset_day(df,'Monday')\n",
    "    print('starts on monday')\n",
    "    print(df.head(3))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveTimeSeries(df,min_date_period,max_date_period,localidad, lenWindow, expName):       \n",
    "    df_values = pd.Series(df['total_eventos']).values\n",
    "    lT=get_LT(df, lenWindow)\n",
    "    df_values = df_values[0:lT]\n",
    "    print(lT, len(df_values))\n",
    "    writeEmbeding(df_values,lenWindow,expName,localidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LT(df_by_period,lenWindow):\n",
    "    min_date = df_by_period.reset_index().date.min()\n",
    "    max_date = df_by_period.reset_index().date.max()\n",
    "    print('min date on localidad',min_date)\n",
    "    print('max date on localidad',max_date)\n",
    "    samples_num = (max_date.date()-min_date.date()).days\n",
    "    print('samples_num',samples_num)\n",
    "    lT = samples_num//lenWindow * lenWindow\n",
    "    print('lT complete',samples_num/lenWindow)\n",
    "    print('lT aprox',samples_num//lenWindow)\n",
    "    return lT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictability_experiment_localidades(df_by_date,min_date_period,max_date_period,lenWindow,localidadesList,Levels,expName,periodName):\n",
    "    workingPath = '/Users/anamaria/Desktop/dev/security_project/periodicity_experiments/predictability/';\n",
    "\n",
    "    flagF = True;\n",
    "    for localidad in localidadesList:\n",
    "        print(localidad)\n",
    "        #write embeding\n",
    "        df_by_localidad = df_by_date[df_by_date['LOCALIDAD'] == localidad]        \n",
    "        df_by_localidad = preprocess_df(df_by_localidad,min_date_period,max_date_period)\n",
    "        saveTimeSeries(df_by_localidad,min_date_period,max_date_period,localidad, lenWindow, expName)\n",
    "        \n",
    "        for nLevels in Levels:\n",
    "            (barcode,timeSeries) = getBarcode(expName,lenWindow,localidad);\n",
    "            binsLevels = np.linspace(np.min(timeSeries),np.max(timeSeries),nLevels);\n",
    "            c,m,p = computeGeneralPredictability(timeSeries,binsLevels,lenWindow)\n",
    "\n",
    "            if flagF==True:\n",
    "                flagF = False\n",
    "                predValues = np.array([expName,periodName,localidad,lenWindow,nLevels,p,m,c]);\n",
    "            else:\n",
    "                predValues = np.vstack((predValues, [expName,periodName,localidad,lenWindow,nLevels,p,m,c]))\n",
    "\n",
    "    return predValues\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_predictability_by_period_report(df_agressiveBehavior,lenWindow,localidadesList,yAxisCategories,name_experiment,nLevel):\n",
    "    join=df_agressiveBehavior.pivot('localidad','period','predictability')\n",
    "    var1_order = []\n",
    "    var2_order = yAxisCategories\n",
    "    if len(var2_order) > 0:\n",
    "        join = join.reindex(var2_order, axis=1)\n",
    "    if len(var1_order) > 0:\n",
    "        join = join.reindex(var1_order)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1,sharex=True, sharey=True)\n",
    "    fig.set_size_inches(7, 6)\n",
    "    g=sns.heatmap(join.astype('float'),annot=True,fmt=\".3\",linewidths=0,cmap=\"Blues\",cbar=False)\n",
    "    g.set_yticklabels(g.get_yticklabels(), rotation = 0)\n",
    "    bottom, top = ax.get_ylim()\n",
    "    ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "    file_path = '/Users/anamaria/Desktop/dev/security_project/periodicity_experiments/predictability/figures/'\n",
    "    plt.savefig(file_path+'table_'+str(name_experiment)+'_predictability_time_'+str(lenWindow)+'_levels_'+str(nLevel),dpi=300,bbox_inches = \"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_localidad(ax,df,col_localidad,col_vals,vmin=None,vmax=None):\n",
    "  loc_geo=\"/Users/anamaria/Desktop/dev/security_project/assets/localidades_polygon.json\"\n",
    "  loc_=gpd.read_file(loc_geo)\n",
    "  loc_=loc_.merge(df,left_on='LocNombre',right_on=col_localidad)\n",
    "  loc_.plot(cmap='viridis',column=col_vals,legend=True,ax=ax,vmin=vmin,vmax=vmax)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_predictability(df_crime, crime_level, lenWindow,name_experiment):\n",
    "    subdata = df_crime[df_crime['crime_level']==crime_level]\n",
    "    subdata = subdata[subdata['lenWindow']==str(lenWindow)]\n",
    "    subdata[\"predictability\"] = pd.to_numeric(subdata[\"predictability\"])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12,12))\n",
    "    map_localidad(ax,subdata,'localidad','predictability')\n",
    "    ax.axis('off')\n",
    "    file_path = '/Users/anamaria/Desktop/dev/security_project/periodicity_experiments/predictability/figures/'\n",
    "    plt.savefig(file_path+'map_aggressiveBehavior_localidades'+str(name_experiment)+'_predictability_time_'+str(lenWindow)+'_levels_'+str(crime_level),dpi=300,bbox_inches = \"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_semester_list(year,semester=1):\n",
    "    if semester == 1:\n",
    "        month_list = ['01','02','03','04','05','06']\n",
    "    if semester == 2:\n",
    "        month_list = ['07','08','09','10','11','12']\n",
    "    semester_list = map(lambda m: year+'/'+str(m), month_list)\n",
    "    return (list(semester_list))\n",
    "\n",
    "def build_trimester_list(year,trimester=1):\n",
    "    if trimester == 1:\n",
    "        month_list = ['01','02','03']\n",
    "    if trimester == 2:\n",
    "        month_list = ['04','05','06']\n",
    "    if trimester == 3:\n",
    "        month_list = ['07','08','09']\n",
    "    if trimester == 4:\n",
    "        month_list = ['10','11','12']\n",
    "    trimester_list = map(lambda m: year+'/'+str(m), month_list)\n",
    "    return (list(trimester_list))\n",
    "\n",
    "def build_bimester_list(year,bimester=1):\n",
    "    if bimester == 1:\n",
    "        month_list = ['01','02']\n",
    "    if bimester == 2:\n",
    "        month_list = ['03','04']\n",
    "    if bimester == 3:\n",
    "        month_list = ['05','06']\n",
    "    if bimester == 4:\n",
    "        month_list = ['07','08']\n",
    "    if bimester == 5:\n",
    "        month_list = ['09','10']\n",
    "    if bimester == 6:\n",
    "        month_list = ['11','12']\n",
    "    bimester_list = map(lambda m: year+'/'+str(m), month_list)\n",
    "    return (list(bimester_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = '/Users/anamaria/Desktop/dev/security_project/datasets/verify_enrich_nuse_29112019.csv'\n",
    "df_input = pd.read_csv(data_location,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input['date']=pd.to_datetime(df_input['FECHA'])\n",
    "df_by_date = pd.DataFrame(df_input.groupby(['date','PERIODO_TS','LOCALIDAD']).size(),columns=[\"total_eventos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_date = df_by_date.reset_index().set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localidades, semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Levels=[3]\n",
    "lenWindow = 7\n",
    "levelCategories = list(map(lambda x: str(x), Levels))\n",
    "localidadesList = list(df_by_date.LOCALIDAD.unique())\n",
    "localidadesList.remove('SIN LOCALIZACION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(df_input['ANIO'].unique())\n",
    "years.remove(2019)\n",
    "semesters = [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predValues_array = []\n",
    "for year in years:\n",
    "    for semester in semesters:\n",
    "        period_list = build_semester_list(str(year),semester)\n",
    "        print(period_list)\n",
    "        df_by_period=df_by_date[df_by_date.PERIODO_TS.isin(period_list)]\n",
    "        #df_by_period = set_initial_dataset_day(df_by_period,'Monday')\n",
    "\n",
    "        min_date_on_period = df_by_period.reset_index().date.min()\n",
    "        max_date_on_period = df_by_period.reset_index().date.max()\n",
    "        print('min date on period',min_date_on_period)\n",
    "        print('max_date_on_period',max_date_on_period)\n",
    "\n",
    "        expName = 'aggressiveBehavior_localidad_by_semester'\n",
    "        periodName = str(year)+'-'+str(semester)\n",
    "        predValues = predictability_experiment_localidades(df_by_period,min_date_on_period,max_date_on_period,lenWindow,localidadesList,Levels,expName,periodName)\n",
    "        predValues_array = predValues_array + list(predValues)\n",
    "    \n",
    "df_prediction = pd.DataFrame(predValues_array, columns=['experiment_name','period','localidad','lenWindow','crime_level','predictability','contingency','constancy'])\n",
    "periodCategories = list(df_prediction['period'].unique())\n",
    "table_predictability_by_period_report(df_prediction,lenWindow,localidadesList,periodCategories,expName,Levels[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localidades, trimester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Levels=[5]\n",
    "lenWindow = 7\n",
    "levelCategories = list(map(lambda x: str(x), Levels))\n",
    "localidadesList = list(df_by_date.LOCALIDAD.unique())\n",
    "localidadesList.remove('SIN LOCALIZACION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(df_input['ANIO'].unique())\n",
    "years.remove(2019)\n",
    "trimesters = [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predValues_array = []\n",
    "for year in years:\n",
    "    for trimester in trimesters:\n",
    "        period_list = build_trimester_list(str(year),trimester)\n",
    "        print(period_list)\n",
    "        df_by_period=df_by_date[df_by_date.PERIODO_TS.isin(period_list)]\n",
    "        #df_by_period = set_initial_dataset_day(df_by_period,'Monday')\n",
    "\n",
    "        min_date_on_period = df_by_period.reset_index().date.min()\n",
    "        max_date_on_period = df_by_period.reset_index().date.max()\n",
    "        print(min_date_on_period,max_date_on_period)\n",
    "\n",
    "        expName = 'aggressiveBehavior_localidad_by_trimester'\n",
    "        periodName = str(year)+'-'+str(trimester)\n",
    "        predValues = predictability_experiment_localidades(df_by_period,min_date_on_period,max_date_on_period,lenWindow,localidadesList,Levels,expName,periodName)\n",
    "        predValues_array = predValues_array + list(predValues)\n",
    "    \n",
    "df_prediction = pd.DataFrame(predValues_array, columns=['experiment_name','period','localidad','lenWindow','crime_level','predictability','contingency','constancy'])\n",
    "periodCategories = list(df_prediction['period'].unique())\n",
    "table_predictability_by_period_report(df_prediction,lenWindow,localidadesList,periodCategories,expName,Levels[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localidades, bimester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Levels=[5]\n",
    "lenWindow = 7\n",
    "levelCategories = list(map(lambda x: str(x), Levels))\n",
    "localidadesList = list(df_by_date.LOCALIDAD.unique())\n",
    "localidadesList.remove('SIN LOCALIZACION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(df_input['ANIO'].unique())\n",
    "years.remove(2019)\n",
    "bimesters = [1, 2, 3, 4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predValues_array = []\n",
    "for year in years:\n",
    "    for bimester in bimesters:\n",
    "        period_list = build_bimester_list(str(year),bimester)\n",
    "        print(period_list)\n",
    "        df_by_period=df_by_date[df_by_date.PERIODO_TS.isin(period_list)]\n",
    "        #df_by_period = set_initial_dataset_day(df_by_period,'Monday')\n",
    "\n",
    "        min_date_on_period = df_by_period.reset_index().date.min()\n",
    "        max_date_on_period = df_by_period.reset_index().date.max()\n",
    "        print(min_date_on_period,max_date_on_period)\n",
    "\n",
    "        expName = 'aggressiveBehavior_localidad_by_bimester'\n",
    "        periodName = str(year)+'-'+str(bimester)\n",
    "        predValues = predictability_experiment_localidades(df_by_period,min_date_on_period,max_date_on_period,lenWindow,localidadesList,Levels,expName,periodName)\n",
    "        predValues_array = predValues_array + list(predValues)\n",
    "    \n",
    "df_prediction = pd.DataFrame(predValues_array, columns=['experiment_name','period','localidad','lenWindow','crime_level','predictability','contingency','constancy'])\n",
    "periodCategories = list(df_prediction['period'].unique())\n",
    "table_predictability_by_period_report(df_prediction,lenWindow,localidadesList,periodCategories,expName,Levels[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
