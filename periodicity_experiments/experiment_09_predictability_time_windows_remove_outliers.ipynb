{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment description\n",
    "## Hypothesis: \n",
    "The amount of predictability of aggressive behavior occurrence in the city is bigger for three crime Levels and in a bimester.\n",
    "\n",
    "## Method: \n",
    "- Remove outliers\n",
    "- Use of predictability for different time windows and crime levels.\n",
    "\n",
    "## Parameters: \n",
    "- Time windows: 7, 14, 28, 84\n",
    "- Crime levels: 3, 5, 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-in methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import math\n",
    "from math import pi\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_initial_dataset_day(df_by_date,name_day):\n",
    "    df_by_date = df_by_date.reset_index()\n",
    "    df_by_date['day_of_week'] = df_by_date['date'].dt.day_name()\n",
    "    monday_idx = df_by_date.index[df_by_date['day_of_week'] == name_day].tolist()[0]\n",
    "    df_by_date = df_by_date[monday_idx:].set_index('date').drop(['day_of_week'],axis=1)\n",
    "    return df_by_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://plot.ly/python/v3/fft-filters/\n",
    "def low_pass_filter(signal_values, fc =0.04, b =0.08):\n",
    "    N = int(np.ceil((4 / b)))\n",
    "    if not N % 2: N += 1\n",
    "    n = np.arange(N)\n",
    "\n",
    "    sinc_func = np.sinc(2 * fc * (n - (N - 1) / 2.))\n",
    "    window = 0.42 - 0.5 * np.cos(2 * np.pi * n / (N - 1)) + 0.08 * np.cos(4 * np.pi * n / (N - 1))\n",
    "    sinc_func = sinc_func * window\n",
    "    sinc_func = sinc_func / np.sum(sinc_func)\n",
    "\n",
    "    s = signal_values\n",
    "    s = s - np.nanmean(s)\n",
    "    filtered_signal = np.convolve(s, sinc_func)\n",
    "    return filtered_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods for slicing windows\n",
    "def im2patches(im,n):\n",
    "    patches = [];\n",
    "    for i in range(len(im)-n):\n",
    "        patch = im[i:(i+n-1)]        \n",
    "        patch = patch - np.nanmean(patch);\n",
    "        if(np.linalg.norm(patch)>0):\n",
    "            patch = patch/np.linalg.norm(patch);\n",
    "        if i==0:\n",
    "            patches = patch;\n",
    "        else:\n",
    "            patches = np.vstack((patches,patch))\n",
    "    return patches;\n",
    "\n",
    "\n",
    "def writeEmbeding(timeSeries,lenWindow,samplePath):\n",
    "    slicingWindows = im2patches(timeSeries,lenWindow);\n",
    "    workingPath = '/Users/anamaria/Desktop/dev/security_project/periodicity_experiments/predictability/slicing/'\n",
    "    prevStation = str(samplePath);\n",
    "    with open(workingPath+'slicingWindows'+\"_\"+str(prevStation)+\"_\"+str(lenWindow)+'_.pickle', 'wb') as f:\n",
    "        lv = slicingWindows.tolist();                        \n",
    "        pickle.dump(lv, f, protocol=2)\n",
    "\n",
    "    workingPath = '/Users/anamaria/Desktop/dev/security_project/periodicity_experiments/predictability/timeSeries/'    \n",
    "    with open(workingPath+'timeSeries'+\"_\"+str(prevStation)+\"_\"+str(lenWindow)+'_.pickle', 'wb') as f:\n",
    "        lv = timeSeries.tolist();                        \n",
    "        pickle.dump(lv, f, protocol=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Methods for predictability\n",
    "def getBarcode(samplePath,lenWindow):\n",
    "    barcode = [];\n",
    "\n",
    "    with open(workingPath+'timeSeries/'+'timeSeries_'+samplePath+'_'+str(lenWindow)+'_'+'.pickle', 'rb') as f:\n",
    "            timeSeries = pickle.load(f);            \n",
    "    return (barcode,timeSeries);\n",
    "\n",
    "def computeBarcodeEntropy(barsLenB0):\n",
    "    barlen = np.array(barsLenB0);\n",
    "    barlen = barlen/barlen.sum();\n",
    "    hbc = 0;\n",
    "    for i in range(barlen.shape[0]):\n",
    "        if barlen[i]!=0:\n",
    "            hbc = hbc-(barlen[i])*np.log(barlen[i]);\n",
    "    return hbc;\n",
    "\n",
    "\n",
    "def computeGeneralPredictability(timeSeries,binsData,lenWindow):\n",
    "    # Colwell, R. K. (1974). Predictability, constancy, and contingency of periodic phenomena. Ecology, 55(5), 1148-1153.\n",
    "    # Normalize the caudal values\n",
    "    nLevels = binsData.shape[0]-1;\n",
    "    matStations = np.array(timeSeries).reshape((np.array(timeSeries).shape[0]//lenWindow,lenWindow))    \n",
    "\n",
    "    grandMean = np.mean(np.mean(matStations));\n",
    "    #matStations = matStations / grandMean;\n",
    "    N = np.zeros((nLevels,lenWindow));\n",
    "    for i in range(1,matStations.shape[1]): \n",
    "        # Computes histograms per columns\n",
    "        hist, bin_edges = np.histogram(matStations[:,i],bins = binsData);\n",
    "        N[:,i] = hist;\n",
    "    X = np.sum(N, axis=0);\n",
    "    Y = np.sum(N, axis=1);\n",
    "    Z = np.sum(Y);\n",
    "    hx = 0;\n",
    "    hy = 0;\n",
    "    hxy = 0;\n",
    "    for j in range(X.shape[0]):\n",
    "        if X[j]!=0:\n",
    "            hx = hx-(X[j]/Z)*np.log(X[j]/Z);\n",
    "            \n",
    "    for i in range(Y.shape[0]):\n",
    "        if Y[i]!=0:\n",
    "            hy = hy-(Y[i]/Z)*np.log(Y[i]/Z);\n",
    "            \n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(X.shape[0]):\n",
    "            if N[i,j]!=0:\n",
    "                hxy = hxy-((N[i,j]/Z)*np.log(N[i,j]/Z));    \n",
    "    \n",
    "    # predictability\n",
    "    p = 1 - (hxy - hx)/np.log(N.shape[0]);\n",
    "    # constancy\n",
    "    c = 1 - hy/np.log(N.shape[0]);\n",
    "    # Returns constancy and contingency\n",
    "    return (c,p-c,p);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    #Remove outliers\n",
    "    q_hi = df[\"total_eventos\"].quantile(0.99)\n",
    "    df = df[(df[\"total_eventos\"] < q_hi)]\n",
    "        \n",
    "    #Make sure dataset starts on Monday for the experiment\n",
    "    df = set_initial_dataset_day(df,'Monday')\n",
    "\n",
    "    #Make sure dataset include consecutive dates in period\n",
    "    idx = pd.date_range(min(df.reset_index().date), max(df.reset_index().date))\n",
    "    df = df.reindex(idx, fill_value=int(df[\"total_eventos\"].mean()))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = '/Users/anamaria/Desktop/dev/security_project/datasets/verify_enrich_nuse_29112019.csv'\n",
    "df_input = pd.read_csv(data_location,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input['date']=pd.to_datetime(df_input['FECHA'])\n",
    "df_by_date = pd.DataFrame(df_input.groupby('date').size(),columns=[\"total_eventos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove outliers and be sure dataset starts on Monday for the experiment\n",
    "df_by_date = preprocess_df(df_by_date)\n",
    "df_by_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Levels=[3,5,10]\n",
    "levelCategories = list(map(lambda x: str(x), Levels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_days_values = pd.Series(df_by_date['total_eventos']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(df_days_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeWindows = [7, 14, 28, 84]\n",
    "windowsCategories = list(map(lambda x: str(x), timeWindows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#lT should be a multiple of each time window (mcm timeWindows and calculate the maximum of points on dataset that are multiple of mcm)\n",
    "lT = 756\n",
    "df_days_values = df_days_values[0:756]\n",
    "len(df_days_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lenWindow in timeWindows:\n",
    "    print(len(df_days_values))\n",
    "    writeEmbeding(df_days_values[0:lT],lenWindow,'aggressiveBehavior_BOGOTA_no_outliers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find predictability, constancy and contingency\n",
    "workingPath = '/Users/anamaria/Desktop/dev/security_project/periodicity_experiments/predictability/';\n",
    "\n",
    "flagF = True;\n",
    "for lenWindow in timeWindows:        \n",
    "    for nLevels in Levels:\n",
    "        for expName in ['aggressiveBehavior_BOGOTA_no_outliers']:\n",
    "            (barcode,timeSeries) = getBarcode(expName,lenWindow);\n",
    "            binsLevels = np.linspace(np.min(timeSeries),np.max(timeSeries),nLevels);\n",
    "            \n",
    "            ## Characterization for B0\n",
    "            #print('--------------------------')\n",
    "            #print('Characterization of '+expName)\n",
    "            plt.figure(figsize=(2.2,1.1))\n",
    "            plt.plot(timeSeries)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.figure()\n",
    "            \n",
    "            c,m,p = computeGeneralPredictability(timeSeries,binsLevels,lenWindow)\n",
    "\n",
    "            if flagF==True:\n",
    "                flagF = False\n",
    "                predValues = np.array([expName,lenWindow,nLevels,p,m,c]);\n",
    "            else:\n",
    "                predValues = np.vstack((predValues, [expName,lenWindow,nLevels,p,m,c]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction = pd.DataFrame(predValues, columns=['crime_type','lenWindow','crime_level','predictability','contingency','constancy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agressiveBehavior = df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join=df_agressiveBehavior.pivot('lenWindow','crime_level','predictability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1_order = windowsCategories\n",
    "var2_order = levelCategories\n",
    "if len(var2_order) > 0:\n",
    "    join = join.reindex(var2_order, axis=1)\n",
    "if len(var1_order) > 0:\n",
    "    join = join.reindex(var1_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,sharex=True, sharey=True)\n",
    "fig.set_size_inches(4, 4)\n",
    "g=sns.heatmap(join.astype('float'),annot=True,fmt=\".3\",linewidths=0,cmap=\"Blues\",cbar=False)\n",
    "g.set_yticklabels(g.get_yticklabels(), rotation = 0)\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "file_path = '/Users/anamaria/Desktop/dev/security_project/periodicity_experiments/predictability/figures/'\n",
    "plt.savefig(file_path+'table_aggressiveBehavior_timeWindows_predictability_no_outliers',dpi=300,bbox_inches = \"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
