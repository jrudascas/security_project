{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment description\n",
    "## Hypothesis: \n",
    "General predictability values related to rnmc database are similar to the ones reported from nuse analysis (experiment 08)\n",
    "## Method: \n",
    "- Select rnmc registers 2017-2018\n",
    "- Remove outliers > q=0.99, assign new max values to outliers\n",
    "- Assign 0 for empty dates\n",
    "- Compare predictability values with the ones obtained on experiment 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-in methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import math\n",
    "from math import pi\n",
    "import geopandas as gpd\n",
    "#from matplotlib.collections import PatchCollection\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workingPath= '/Users/anamaria/Desktop/dev/security_project/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_initial_dataset_day(df_by_date,name_day):\n",
    "    df_by_date = df_by_date.reset_index()\n",
    "    df_by_date['day_of_week'] = df_by_date['date'].dt.day_name()\n",
    "    monday_idx = df_by_date.index[df_by_date['day_of_week'] == name_day].tolist()[0]\n",
    "    df_by_date = df_by_date[monday_idx:].set_index('date').drop(['day_of_week'],axis=1)\n",
    "    return df_by_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods for time windows\n",
    "def im2patches(im,n):\n",
    "    patches = [];\n",
    "    for i in range(len(im)-n):\n",
    "        patch = im[i:(i+n-1)]        \n",
    "        patch = patch - np.nanmean(patch);\n",
    "        if(np.linalg.norm(patch)>0):\n",
    "            patch = patch/np.linalg.norm(patch);\n",
    "        if i==0:\n",
    "            patches = patch;\n",
    "        else:\n",
    "            patches = np.vstack((patches,patch))\n",
    "    return patches;\n",
    "\n",
    "def writeEmbeding(timeSeries,lenWindow,samplePath, scenarioName):\n",
    "    slicingWindows = im2patches(timeSeries,lenWindow);\n",
    "    experimentPath = 'periodicity_experiments/predictability/slicing/'\n",
    "    prevStation = str(samplePath);\n",
    "    with open(workingPath+experimentPath+'slicingWindows'+\"_\"+str(prevStation)+\"_\"+str(scenarioName)+\"_\"+str(lenWindow)+'_.pickle', 'wb') as f:\n",
    "        lv = slicingWindows.tolist();                        \n",
    "        pickle.dump(lv, f, protocol=2)\n",
    "\n",
    "    experimentPath = 'periodicity_experiments/predictability/timeSeries/'    \n",
    "    with open(workingPath+experimentPath+'timeSeries'+\"_\"+str(prevStation)+\"_\"+str(scenarioName)+\"_\"+str(lenWindow)+'_.pickle', 'wb') as f:\n",
    "        lv = timeSeries.tolist();                        \n",
    "        pickle.dump(lv, f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Methods for predictability\n",
    "def getBarcode(samplePath,lenWindow,scenarioName):\n",
    "    experimentPath = 'periodicity_experiments/predictability/'\n",
    "    barcode = [];\n",
    "\n",
    "    with open(workingPath+experimentPath+'timeSeries/'+'timeSeries_'+samplePath+\"_\"+str(scenarioName)+'_'+str(lenWindow)+'_'+'.pickle', 'rb') as f:\n",
    "            timeSeries = pickle.load(f);            \n",
    "    return (barcode,timeSeries);\n",
    "\n",
    "def computeBarcodeEntropy(barsLenB0):\n",
    "    barlen = np.array(barsLenB0);\n",
    "    barlen = barlen/barlen.sum();\n",
    "    hbc = 0;\n",
    "    for i in range(barlen.shape[0]):\n",
    "        if barlen[i]!=0:\n",
    "            hbc = hbc-(barlen[i])*np.log(barlen[i]);\n",
    "    return hbc;\n",
    "\n",
    "\n",
    "def computeGeneralPredictability(timeSeries,binsData,lenWindow):\n",
    "    # Colwell, R. K. (1974). Predictability, constancy, and contingency of periodic phenomena. Ecology, 55(5), 1148-1153.\n",
    "    # Normalize the caudal values\n",
    "    nLevels = binsData.shape[0]-1;\n",
    "    matStations = np.array(timeSeries).reshape((np.array(timeSeries).shape[0]//lenWindow,lenWindow))    \n",
    "\n",
    "    grandMean = np.mean(np.mean(matStations));\n",
    "    #matStations = matStations / grandMean;\n",
    "    N = np.zeros((nLevels,lenWindow));\n",
    "    for i in range(1,matStations.shape[1]): \n",
    "        # Computes histograms per columns\n",
    "        hist, bin_edges = np.histogram(matStations[:,i],bins = binsData);\n",
    "        N[:,i] = hist;\n",
    "    X = np.sum(N, axis=0);\n",
    "    Y = np.sum(N, axis=1);\n",
    "    Z = np.sum(Y);\n",
    "    hx = 0;\n",
    "    hy = 0;\n",
    "    hxy = 0;\n",
    "    for j in range(X.shape[0]):\n",
    "        if X[j]!=0:\n",
    "            hx = hx-(X[j]/Z)*np.log(X[j]/Z);\n",
    "            \n",
    "    for i in range(Y.shape[0]):\n",
    "        if Y[i]!=0:\n",
    "            hy = hy-(Y[i]/Z)*np.log(Y[i]/Z);\n",
    "            \n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(X.shape[0]):\n",
    "            if N[i,j]!=0:\n",
    "                hxy = hxy-((N[i,j]/Z)*np.log(N[i,j]/Z));    \n",
    "    \n",
    "    # predictability\n",
    "    p = 1 - (hxy - hx)/np.log(N.shape[0]);\n",
    "    # constancy\n",
    "    c = 1 - hy/np.log(N.shape[0]);\n",
    "    # Returns constancy and contingency\n",
    "    return (c,p-c,p);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df,min_date_period,max_date_period):\n",
    "    df=df.drop(columns=['NOMBRE_LOCALIDAD'])\n",
    "    #Remove outliers\n",
    "    q_hi = df[\"total_eventos\"].quantile(0.99)\n",
    "    #df = df[(df[\"total_eventos\"] < q_hi)]\n",
    "    \n",
    "    ### Comment this code section if previous line is uncommented\n",
    "    df_without_outliers = df[(df[\"total_eventos\"] < q_hi)]\n",
    "    max_value = df_without_outliers['total_eventos'].max()\n",
    "    df.loc[df[\"total_eventos\"]>= q_hi,'total_eventos'] = max_value\n",
    "    ###\n",
    "\n",
    "    #Make sure dataset include consecutive dates in period\n",
    "    idx = pd.date_range(min_date_period, max_date_period)\n",
    "    #df = df.reindex(idx, fill_value=int(df[\"total_eventos\"].mean()))\n",
    "    df = df.reindex(idx, fill_value=int(0))\n",
    "    df = df.reset_index().rename(columns={'index': 'date'}).set_index('date')\n",
    "    \n",
    "    #Make sure dataset starts on Monday for the experiment\n",
    "    df = set_initial_dataset_day(df,'Monday')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveTimeSeries(df,min_date_period,max_date_period,localidad, lenWindow, expName):       \n",
    "    df_values = pd.Series(df['total_eventos']).values\n",
    "    lT=get_LT(df, lenWindow)\n",
    "    df_values = df_values[0:lT]\n",
    "    writeEmbeding(df_values,lenWindow,expName,localidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LT(df_by_period,lenWindow):\n",
    "    min_date = df_by_period.reset_index().date.min()\n",
    "    max_date = df_by_period.reset_index().date.max()\n",
    "    samples_num = (max_date.date()-min_date.date()).days\n",
    "    lT = samples_num//lenWindow * lenWindow\n",
    "    return lT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictability_experiment_localidades(df_by_date,min_date_period,max_date_period,lenWindow,localidadesList,Levels,expName,periodName):\n",
    "    #workingPath = '/Users/anamaria/Desktop/dev/security_project/periodicity_experiments/predictability/';\n",
    "\n",
    "    flagF = True;\n",
    "    for localidad in localidadesList:\n",
    "        #write embeding\n",
    "        df_by_localidad = df_by_date[df_by_date['NOMBRE_LOCALIDAD'] == localidad]        \n",
    "        df_by_localidad = preprocess_df(df_by_localidad,min_date_period,max_date_period)\n",
    "        #print(df_by_localidad[\"total_eventos\"])\n",
    "        saveTimeSeries(df_by_localidad,min_date_period,max_date_period,localidad, lenWindow, expName)\n",
    "        \n",
    "        for nLevels in Levels:\n",
    "            (barcode,timeSeries) = getBarcode(expName,lenWindow,localidad);\n",
    "            binsLevels = np.linspace(np.min(timeSeries),np.max(timeSeries),nLevels);\n",
    "            c,m,p = computeGeneralPredictability(timeSeries,binsLevels,lenWindow)\n",
    "\n",
    "            if flagF==True:\n",
    "                flagF = False\n",
    "                predValues = np.array([expName,periodName,localidad,lenWindow,nLevels,p,m,c]);\n",
    "            else:\n",
    "                predValues = np.vstack((predValues, [expName,periodName,localidad,lenWindow,nLevels,p,m,c]))\n",
    "\n",
    "    return predValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_predictability_report(df_agressiveBehavior,lenWindow,localidadesList,levelCategories,name_experiment):\n",
    "    join=df_agressiveBehavior.pivot('localidad','crime_level','predictability')\n",
    "    var1_order = []\n",
    "    var2_order = levelCategories\n",
    "    if len(var2_order) > 0:\n",
    "        join = join.reindex(var2_order, axis=1)\n",
    "    if len(var1_order) > 0:\n",
    "        join = join.reindex(var1_order)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1,sharex=True, sharey=True)\n",
    "    fig.set_size_inches(7, 6)\n",
    "    g=sns.heatmap(join.astype('float'),annot=True,fmt=\".3\",linewidths=0,cmap=\"Blues\",cbar=False)\n",
    "    g.set_yticklabels(g.get_yticklabels(), rotation = 0)\n",
    "    bottom, top = ax.get_ylim()\n",
    "    ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "    file_path = 'periodicity_experiments/predictability/figures/'\n",
    "    #plt.savefig(workingPath+file_path+'table_aggressiveBehavior_localidades'+str(name_experiment)+'_predictability_time_'+str(lenWindow)+'_levels_'+str(levelCategories),dpi=300,bbox_inches = \"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_constancy_report(df_agressiveBehavior,lenWindow,localidadesList,levelCategories,name_experiment):\n",
    "    join=df_agressiveBehavior.pivot('localidad','crime_level','constancy')\n",
    "    var1_order = []\n",
    "    var2_order = levelCategories\n",
    "    if len(var2_order) > 0:\n",
    "        join = join.reindex(var2_order, axis=1)\n",
    "    if len(var1_order) > 0:\n",
    "        join = join.reindex(var1_order)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1,sharex=True, sharey=True)\n",
    "    fig.set_size_inches(7, 6)\n",
    "    g=sns.heatmap(join.astype('float'),annot=True,fmt=\".3\",linewidths=0,cmap=\"Blues\",cbar=False)\n",
    "    g.set_yticklabels(g.get_yticklabels(), rotation = 0)\n",
    "    bottom, top = ax.get_ylim()\n",
    "    ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "    file_path = 'periodicity_experiments/predictability/figures/'\n",
    "    plt.savefig(workingPath+file_path+'table_aggressiveBehavior_localidades'+str(name_experiment)+'_constancy_time_'+str(lenWindow)+'_levels_'+str(levelCategories),dpi=300,bbox_inches = \"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_contingency_report(df_agressiveBehavior,lenWindow,localidadesList,levelCategories,name_experiment):\n",
    "    join=df_agressiveBehavior.pivot('localidad','crime_level','contingency')\n",
    "    var1_order = []\n",
    "    var2_order = levelCategories\n",
    "    if len(var2_order) > 0:\n",
    "        join = join.reindex(var2_order, axis=1)\n",
    "    if len(var1_order) > 0:\n",
    "        join = join.reindex(var1_order)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1,sharex=True, sharey=True)\n",
    "    fig.set_size_inches(7, 6)\n",
    "    g=sns.heatmap(join.astype('float'),annot=True,fmt=\".3\",linewidths=0,cmap=\"Blues\",cbar=False)\n",
    "    g.set_yticklabels(g.get_yticklabels(), rotation = 0)\n",
    "    bottom, top = ax.get_ylim()\n",
    "    ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "    file_path = 'periodicity_experiments/predictability/figures/'\n",
    "    plt.savefig(workingPath+file_path+'table_aggressiveBehavior_localidades'+str(name_experiment)+'_contingency_time_'+str(lenWindow)+'_levels_'+str(levelCategories),dpi=300,bbox_inches = \"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_predictability_measures(df,lenWindow,crime_level,name_experiment):\n",
    "    join=df.pivot('localidad','variable','value')\n",
    "    var1_order = []\n",
    "    var2_order = []\n",
    "    if len(var2_order) > 0:\n",
    "        join = join.reindex(var2_order, axis=1)\n",
    "    if len(var1_order) > 0:\n",
    "        join = join.reindex(var1_order)\n",
    "\n",
    "    fig, ax = plt.subplots(1,1,sharex=True, sharey=True)\n",
    "    fig.set_size_inches(7, 6)\n",
    "    g=sns.heatmap(join.astype('float'),annot=True,fmt=\".3\",linewidths=0,cmap=\"Blues\",cbar=False)\n",
    "    g.set_yticklabels(g.get_yticklabels(), rotation = 0)\n",
    "    bottom, top = ax.get_ylim()\n",
    "    ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "    file_path = 'periodicity_experiments/predictability/figures/'\n",
    "    #plt.savefig(workingPath+file_path+'table_aggressiveBehavior_localidades'+str(name_experiment)+'_predict_measures_time_'+str(lenWindow)+'_crime_'+str(crime_level),dpi=300,bbox_inches = \"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_localidad(ax,df,col_localidad,col_vals,vmin=None,vmax=None):\n",
    "    loc_geo=workingPath+\"assets/localidades_polygon.json\"\n",
    "    loc_=gpd.read_file(loc_geo)\n",
    "    loc_=loc_.merge(df,left_on='LocNombre',right_on=col_localidad)\n",
    "    loc_.plot(cmap='viridis',edgecolor='white',column=col_vals,ax=ax,vmin=vmin,vmax=vmax,legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_predictability(df_crime, crime_level, lenWindow,name_experiment):\n",
    "    subdata = df_crime[df_crime['crime_level']==crime_level]\n",
    "    subdata = subdata[subdata['lenWindow']==str(lenWindow)]\n",
    "    subdata[\"predictability\"] = pd.to_numeric(subdata[\"predictability\"])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12,12))\n",
    "    map_localidad(ax,subdata,'localidad','predictability',vmin=0,vmax=0.45)\n",
    "    ax.axis('off')\n",
    "    file_path = 'periodicity_experiments/predictability/figures/'\n",
    "    #plt.savefig(workingPath+file_path+'map_aggressiveBehavior_localidades'+str(name_experiment)+'_predictability_time_'+str(lenWindow)+'_levels_'+str(crime_level),dpi=300,bbox_inches = \"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = '/Users/anamaria/Desktop/dev/security_project/datasets/06. verify_enrich_rnmc_12022020.csv'\n",
    "df_input = pd.read_csv(data_location,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input.TIPO_PRIORIZACION.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_period = df_input[df_input['ANIO']!=2019]\n",
    "df_period.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_period['date']=pd.to_datetime(df_period['FECHA'])\n",
    "df_by_date = pd.DataFrame(df_period.groupby(['date','NOMBRE_LOCALIDAD']).size(),columns=[\"total_eventos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_date = df_by_date.reset_index().set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment to validate H1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Levels=[3,5,10]\n",
    "levelCategories = list(map(lambda x: str(x), Levels))\n",
    "localidadesList = list(df_by_date.NOMBRE_LOCALIDAD.unique())\n",
    "localidadesList.remove('SUMAPAZ')\n",
    "timeWindows = [7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localidadesList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for lenWindow in timeWindows:\n",
    "    expName = '_localidades_rnmc_'\n",
    "    periodName = '2017-2018'\n",
    "    min_date_on_period = df_by_date.reset_index().date.min()\n",
    "    max_date_on_period = df_by_date.reset_index().date.max()\n",
    "    predValues = predictability_experiment_localidades(df_by_date,min_date_on_period,max_date_on_period,lenWindow,localidadesList,Levels,expName,periodName)\n",
    "    df_prediction = pd.DataFrame(predValues, columns=['experiment_name','period','localidad','lenWindow','crime_level','predictability','contingency','constancy'])\n",
    "    table_predictability_report(df_prediction,lenWindow,localidadesList,levelCategories,expName)\n",
    "    #table_constancy_report(df_prediction,lenWindow,localidadesList,levelCategories,name_experiment)\n",
    "    #table_contingency_report(df_prediction,lenWindow,localidadesList,levelCategories,name_experiment)\n",
    "    crime_level = '3'\n",
    "    map_predictability(df_prediction, crime_level, lenWindow, expName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciudad_bolivar=df_by_date[df_by_date['NOMBRE_LOCALIDAD']=='CIUDAD BOLIVAR']\n",
    "min_date_on_period = df_by_date.reset_index().date.min()\n",
    "max_date_on_period = df_by_date.reset_index().date.max()\n",
    "ciudad_bolivar = preprocess_df(ciudad_bolivar,min_date_on_period,max_date_on_period)\n",
    "ciudad_bolivar.head(90).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciudad_bolivar=df_by_date[df_by_date['NOMBRE_LOCALIDAD']=='CIUDAD BOLIVAR']\n",
    "min_date_on_period = df_by_date.reset_index().date.min()\n",
    "max_date_on_period = df_by_date.reset_index().date.max()\n",
    "#ciudad_bolivar = preprocess_df(ciudad_bolivar,min_date_on_period,max_date_on_period)\n",
    "ciudad_bolivar.head(90).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciudad_bolivar.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teusaquillo=df_by_date[df_by_date['NOMBRE_LOCALIDAD']=='TEUSAQUILLO']\n",
    "min_date_on_period = df_by_date.reset_index().date.min()\n",
    "max_date_on_period = df_by_date.reset_index().date.max()\n",
    "teusaquillo = preprocess_df(teusaquillo,min_date_on_period,max_date_on_period)\n",
    "teusaquillo.head(90).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
