{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment description\n",
    "## Hypothesis: \n",
    "Predictability localidad values are similar (presents low variance) among intervals on full dataset\n",
    "\n",
    "## Method: \n",
    "- Remove outliers\n",
    "- Measure predictability for 7 days timewindows and levelCrime=3 on intervals for full dataset (months, bimesters, semesters)\n",
    "- Implement a metric to compare the difference among predictability values\n",
    "\n",
    "## Parameters: \n",
    "- Time windows: 7\n",
    "- Crime levels: 3\n",
    "- Aggregation: localidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-in methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import math\n",
    "from math import pi\n",
    "import geopandas as gpd\n",
    "import plotly.express as px\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workingPath= '/Users/anamaria/Desktop/dev/security_project/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_initial_dataset_day(df_by_date,name_day):\n",
    "    df_by_date = df_by_date.reset_index()\n",
    "    df_by_date['day_of_week'] = df_by_date['date'].dt.day_name()\n",
    "    monday_idx = df_by_date.index[df_by_date['day_of_week'] == name_day].tolist()[0]\n",
    "    df_by_date = df_by_date[monday_idx:].set_index('date').drop(['day_of_week'],axis=1)\n",
    "    return df_by_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods for time windows\n",
    "def im2patches(im,n):\n",
    "    patches = [];\n",
    "    for i in range(len(im)-n):\n",
    "        patch = im[i:(i+n-1)]        \n",
    "        patch = patch - np.nanmean(patch);\n",
    "        if(np.linalg.norm(patch)>0):\n",
    "            patch = patch/np.linalg.norm(patch);\n",
    "        if i==0:\n",
    "            patches = patch;\n",
    "        else:\n",
    "            patches = np.vstack((patches,patch))\n",
    "    return patches;\n",
    "\n",
    "def writeEmbeding(timeSeries,lenWindow,samplePath, scenarioName):\n",
    "    slicingWindows = im2patches(timeSeries,lenWindow);\n",
    "    experimentPath = 'periodicity_experiments/predictability/slicing/'\n",
    "    prevStation = str(samplePath);\n",
    "    with open(workingPath+experimentPath+'slicingWindows'+\"_\"+str(prevStation)+\"_\"+str(scenarioName)+\"_\"+str(lenWindow)+'_.pickle', 'wb') as f:\n",
    "        lv = slicingWindows.tolist();                        \n",
    "        pickle.dump(lv, f, protocol=2)\n",
    "\n",
    "    experimentPath = 'periodicity_experiments/predictability/timeSeries/'    \n",
    "    with open(workingPath+experimentPath+'timeSeries'+\"_\"+str(prevStation)+\"_\"+str(scenarioName)+\"_\"+str(lenWindow)+'_.pickle', 'wb') as f:\n",
    "        lv = timeSeries.tolist();                        \n",
    "        pickle.dump(lv, f, protocol=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Methods for predictability\n",
    "def getBarcode(samplePath,lenWindow,scenarioName):\n",
    "    experimentPath = 'periodicity_experiments/predictability/'\n",
    "    barcode = [];\n",
    "\n",
    "    with open(workingPath+experimentPath+'timeSeries/'+'timeSeries_'+samplePath+\"_\"+str(scenarioName)+'_'+str(lenWindow)+'_'+'.pickle', 'rb') as f:\n",
    "            timeSeries = pickle.load(f);            \n",
    "    return (barcode,timeSeries);\n",
    "\n",
    "def computeBarcodeEntropy(barsLenB0):\n",
    "    barlen = np.array(barsLenB0);\n",
    "    barlen = barlen/barlen.sum();\n",
    "    hbc = 0;\n",
    "    for i in range(barlen.shape[0]):\n",
    "        if barlen[i]!=0:\n",
    "            hbc = hbc-(barlen[i])*np.log(barlen[i]);\n",
    "    return hbc;\n",
    "\n",
    "\n",
    "def computeGeneralPredictability(timeSeries,binsData,lenWindow):\n",
    "    # Colwell, R. K. (1974). Predictability, constancy, and contingency of periodic phenomena. Ecology, 55(5), 1148-1153.\n",
    "    # Normalize the caudal values\n",
    "    nLevels = binsData.shape[0]-1;\n",
    "    matStations = np.array(timeSeries).reshape((np.array(timeSeries).shape[0]//lenWindow,lenWindow))    \n",
    "\n",
    "    grandMean = np.mean(np.mean(matStations));\n",
    "    #matStations = matStations / grandMean;\n",
    "    N = np.zeros((nLevels,lenWindow));\n",
    "    for i in range(1,matStations.shape[1]): \n",
    "        # Computes histograms per columns\n",
    "        hist, bin_edges = np.histogram(matStations[:,i],bins = binsData);\n",
    "        N[:,i] = hist;\n",
    "    X = np.sum(N, axis=0);\n",
    "    Y = np.sum(N, axis=1);\n",
    "    Z = np.sum(Y);\n",
    "    hx = 0;\n",
    "    hy = 0;\n",
    "    hxy = 0;\n",
    "    for j in range(X.shape[0]):\n",
    "        if X[j]!=0:\n",
    "            hx = hx-(X[j]/Z)*np.log(X[j]/Z);\n",
    "            \n",
    "    for i in range(Y.shape[0]):\n",
    "        if Y[i]!=0:\n",
    "            hy = hy-(Y[i]/Z)*np.log(Y[i]/Z);\n",
    "            \n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(X.shape[0]):\n",
    "            if N[i,j]!=0:\n",
    "                hxy = hxy-((N[i,j]/Z)*np.log(N[i,j]/Z));    \n",
    "    \n",
    "    # predictability\n",
    "    p = 1 - (hxy - hx)/np.log(N.shape[0]);\n",
    "    # constancy\n",
    "    c = 1 - hy/np.log(N.shape[0]);\n",
    "    # Returns constancy and contingency\n",
    "    return (c,p-c,p);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df,min_date_period,max_date_period):\n",
    "    df=df.drop(columns=['PERIODO_TS','LOCALIDAD'])\n",
    "    #Remove outliers\n",
    "    q_hi = df[\"total_eventos\"].quantile(0.99)\n",
    "    df = df[(df[\"total_eventos\"] < q_hi)]\n",
    "\n",
    "    #Make sure dataset include consecutive dates in period\n",
    "    idx = pd.date_range(min_date_period, max_date_period)\n",
    "    df = df.reindex(idx, fill_value=int(df[\"total_eventos\"].mean()))\n",
    "    df = df.reset_index().rename(columns={'index': 'date'}).set_index('date')\n",
    "    \n",
    "    #Make sure dataset starts on Monday for the experiment\n",
    "    df = set_initial_dataset_day(df,'Monday')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveTimeSeries(df,min_date_period,max_date_period,localidad, lenWindow, expName):       \n",
    "    df_values = pd.Series(df['total_eventos']).values\n",
    "    lT=get_LT(df, lenWindow)\n",
    "    df_values = df_values[0:lT]\n",
    "    writeEmbeding(df_values,lenWindow,expName,localidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LT(df_by_period,lenWindow):\n",
    "    min_date = df_by_period.reset_index().date.min()\n",
    "    max_date = df_by_period.reset_index().date.max()\n",
    "    samples_num = (max_date.date()-min_date.date()).days\n",
    "    lT = samples_num//lenWindow * lenWindow\n",
    "    return lT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictability_experiment_localidades(df_by_date,min_date_period,max_date_period,lenWindow,localidadesList,Levels,expName,periodName):\n",
    "    #workingPath = '/Users/anamaria/Desktop/dev/security_project/periodicity_experiments/predictability/';\n",
    "\n",
    "    flagF = True;\n",
    "    for localidad in localidadesList:\n",
    "        #write embeding\n",
    "        df_by_localidad = df_by_date[df_by_date['LOCALIDAD'] == localidad]        \n",
    "        df_by_localidad = preprocess_df(df_by_localidad,min_date_period,max_date_period)\n",
    "        #print(df_by_localidad[\"total_eventos\"])\n",
    "        saveTimeSeries(df_by_localidad,min_date_period,max_date_period,localidad, lenWindow, expName)\n",
    "        \n",
    "        for nLevels in Levels:\n",
    "            (barcode,timeSeries) = getBarcode(expName,lenWindow,localidad);\n",
    "            binsLevels = np.linspace(np.min(timeSeries),np.max(timeSeries),nLevels);\n",
    "            c,m,p = computeGeneralPredictability(timeSeries,binsLevels,lenWindow)\n",
    "\n",
    "            if flagF==True:\n",
    "                flagF = False\n",
    "                predValues = np.array([expName,periodName,localidad,lenWindow,nLevels,p,m,c]);\n",
    "            else:\n",
    "                predValues = np.vstack((predValues, [expName,periodName,localidad,lenWindow,nLevels,p,m,c]))\n",
    "\n",
    "    return predValues\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_predictability_variance(df_agressiveBehavior,lenWindow,localidadesList,yAxisCategories,name_experiment,nLevel):\n",
    "    join=df_agressiveBehavior.pivot('localidad','period','p_variance')\n",
    "    var1_order = []\n",
    "    var2_order = yAxisCategories\n",
    "    if len(var2_order) > 0:\n",
    "        join = join.reindex(var2_order, axis=1)\n",
    "    if len(var1_order) > 0:\n",
    "        join = join.reindex(var1_order)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1,sharex=True, sharey=True)\n",
    "    fig.set_size_inches(10, 6)\n",
    "    g=sns.heatmap(join.astype('float'),annot=True,fmt=\".2\",linewidths=0,cmap=\"Blues\",cbar=False)\n",
    "    g.set_yticklabels(g.get_yticklabels(), rotation = 0)\n",
    "    bottom, top = ax.get_ylim()\n",
    "    ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "    file_path = 'periodicity_experiments/predictability/figures/'\n",
    "    plt.savefig(workingPath+file_path+'table_'+str(name_experiment)+'_p_variance_time_'+str(lenWindow)+'_levels_'+str(nLevel),dpi=300,bbox_inches = \"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_localidad(ax,df,col_localidad,col_vals,vmin=None,vmax=None):\n",
    "  loc_geo=workingPath+\"assets/localidades_polygon.json\"\n",
    "  loc_=gpd.read_file(loc_geo)\n",
    "  loc_=loc_.merge(df,left_on='LocNombre',right_on=col_localidad)\n",
    "  loc_.plot(cmap='viridis',column=col_vals,legend=True,ax=ax,vmin=vmin,vmax=vmax)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_predictability(df_crime, crime_level, lenWindow,name_experiment):\n",
    "    subdata = df_crime[df_crime['crime_level']==crime_level]\n",
    "    subdata = subdata[subdata['lenWindow']==str(lenWindow)]\n",
    "    subdata[\"predictability\"] = pd.to_numeric(subdata[\"predictability\"])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12,12))\n",
    "    map_localidad(ax,subdata,'localidad','predictability')\n",
    "    ax.axis('off')\n",
    "    file_path = 'periodicity_experiments/predictability/figures/'\n",
    "    plt.savefig(workingPath+file_path+'map_aggressiveBehavior_localidades'+str(name_experiment)+'_predictability_time_'+str(lenWindow)+'_levels_'+str(crime_level),dpi=300,bbox_inches = \"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_semester_list(year,semester=1):\n",
    "    if semester == 1:\n",
    "        month_list = ['01','02','03','04','05','06']\n",
    "    if semester == 2:\n",
    "        month_list = ['07','08','09','10','11','12']\n",
    "    semester_list = map(lambda m: year+'/'+str(m), month_list)\n",
    "    return (list(semester_list))\n",
    "\n",
    "def build_trimester_list(year,trimester=1):\n",
    "    if trimester == 1:\n",
    "        month_list = ['01','02','03']\n",
    "    if trimester == 2:\n",
    "        month_list = ['04','05','06']\n",
    "    if trimester == 3:\n",
    "        month_list = ['07','08','09']\n",
    "    if trimester == 4:\n",
    "        month_list = ['10','11','12']\n",
    "    trimester_list = map(lambda m: year+'/'+str(m), month_list)\n",
    "    return (list(trimester_list))\n",
    "\n",
    "def build_bimester_list(year,bimester=1):\n",
    "    if bimester == 1:\n",
    "        month_list = ['01','02']\n",
    "    if bimester == 2:\n",
    "        month_list = ['03','04']\n",
    "    if bimester == 3:\n",
    "        month_list = ['05','06']\n",
    "    if bimester == 4:\n",
    "        month_list = ['07','08']\n",
    "    if bimester == 5:\n",
    "        month_list = ['09','10']\n",
    "    if bimester == 6:\n",
    "        month_list = ['11','12']\n",
    "    bimester_list = map(lambda m: year+'/'+str(m), month_list)\n",
    "    return (list(bimester_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = '/Users/anamaria/Desktop/dev/security_project/datasets/06. verify_enrich_nuse_11022020.csv'\n",
    "df_input = pd.read_csv(data_location,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input['date']=pd.to_datetime(df_input['FECHA']).dt.strftime('%Y-%m-%d')\n",
    "df_input['date']=pd.to_datetime(df_input['date'],format='%Y-%m-%d')\n",
    "df_by_date = pd.DataFrame(df_input.groupby(['date','PERIODO_TS','LOCALIDAD']).size(),columns=[\"total_eventos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_date = df_by_date.reset_index().set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localidades, semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Levels=[3]\n",
    "lenWindow = 7\n",
    "levelCategories = list(map(lambda x: str(x), Levels))\n",
    "localidadesList = list(df_by_date.LOCALIDAD.unique())\n",
    "localidadesList.remove('SIN LOCALIZACION')\n",
    "localidadesList.remove('SUMAPAZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(df_input['ANIO'].unique())\n",
    "years.remove(2019)\n",
    "semesters = [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predValues_array = []\n",
    "for year in years:\n",
    "    for semester in semesters:\n",
    "        period_list = build_semester_list(str(year),semester)\n",
    "        print(period_list)\n",
    "        df_by_period=df_by_date[df_by_date.PERIODO_TS.isin(period_list)]\n",
    "\n",
    "        min_date_on_period = df_by_period.reset_index().date.min()\n",
    "        max_date_on_period = df_by_period.reset_index().date.max()\n",
    "\n",
    "        expName = 'aggressiveBehavior_localidad_by_semester_full_dataset'\n",
    "        periodName = str(year)+'-'+str(semester)\n",
    "        predValues = predictability_experiment_localidades(df_by_period,min_date_on_period,max_date_on_period,lenWindow,localidadesList,Levels,expName,periodName)\n",
    "        predValues_array = predValues_array + list(predValues)\n",
    "    \n",
    "df_prediction = pd.DataFrame(predValues_array, columns=['experiment_name','period','localidad','lenWindow','crime_level','predictability','contingency','constancy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction.loc[df_prediction.period.str.contains(\"-1\"), 'semester'] = 'I'\n",
    "df_prediction.loc[df_prediction.period.str.contains(\"-2\"), 'semester'] = 'II'\n",
    "df_prediction[\"year\"] = df_prediction.period.str.extract(r'(\\d{4})')\n",
    "df_prediction['predictability']=pd.to_numeric(df_prediction['predictability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semesterList = df_prediction.semester.unique()\n",
    "flagF = True\n",
    "for localidad in localidadesList:\n",
    "    df_by_localidad = df_prediction.loc[df_prediction['localidad'] == localidad]\n",
    "    for semester in semesterList:\n",
    "        df_by_period = df_by_localidad.loc[df_by_localidad['semester'] == semester]\n",
    "        meanPredictability = df_by_period.loc[:,\"predictability\"].mean()\n",
    "        currentVariance = df_by_period.loc[:,\"predictability\"].var()\n",
    "        if flagF==True:\n",
    "            flagF = False\n",
    "            varValues = np.array([localidad,semester,meanPredictability,currentVariance]);\n",
    "        else:\n",
    "            varValues = np.vstack((varValues, [localidad,semester,meanPredictability,currentVariance]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_variance_prediction = pd.DataFrame(varValues, columns=['localidad','period','p','p_variance'])\n",
    "periodCategories = list(df_variance_prediction['period'].unique())\n",
    "table_predictability_variance(df_variance_prediction,lenWindow,localidadesList,periodCategories,expName,Levels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localidades, trimester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Levels=[3]\n",
    "lenWindow = 7\n",
    "levelCategories = list(map(lambda x: str(x), Levels))\n",
    "localidadesList = list(df_by_date.LOCALIDAD.unique())\n",
    "localidadesList.remove('SIN LOCALIZACION')\n",
    "localidadesList.remove('SUMAPAZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(df_input['ANIO'].unique())\n",
    "years.remove(2019)\n",
    "trimesters = [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predValues_array = []\n",
    "for year in years:\n",
    "    for trimester in trimesters:\n",
    "        period_list = build_trimester_list(str(year),trimester)\n",
    "        print(period_list)\n",
    "        df_by_period=df_by_date[df_by_date.PERIODO_TS.isin(period_list)]\n",
    "\n",
    "        min_date_on_period = df_by_period.reset_index().date.min()\n",
    "        max_date_on_period = df_by_period.reset_index().date.max()\n",
    "\n",
    "        expName = 'aggressiveBehavior_localidad_by_trimester_full_dataset'\n",
    "        periodName = str(year)+'-'+str(trimester)\n",
    "        predValues = predictability_experiment_localidades(df_by_period,min_date_on_period,max_date_on_period,lenWindow,localidadesList,Levels,expName,periodName)\n",
    "        predValues_array = predValues_array + list(predValues)\n",
    "    \n",
    "df_prediction = pd.DataFrame(predValues_array, columns=['experiment_name','period','localidad','lenWindow','crime_level','predictability','contingency','constancy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction.loc[df_prediction.period.str.contains(\"-1\"), 'trimester'] = 'I'\n",
    "df_prediction.loc[df_prediction.period.str.contains(\"-2\"), 'trimester'] = 'II'\n",
    "df_prediction.loc[df_prediction.period.str.contains(\"-3\"), 'trimester'] = 'III'\n",
    "df_prediction.loc[df_prediction.period.str.contains(\"-4\"), 'trimester'] = 'IV'\n",
    "df_prediction[\"year\"] = df_prediction.period.str.extract(r'(\\d{4})')\n",
    "df_prediction['predictability']=pd.to_numeric(df_prediction['predictability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimesterList = df_prediction.trimester.unique()\n",
    "flagF = True\n",
    "for localidad in localidadesList:\n",
    "    df_by_localidad = df_prediction.loc[df_prediction['localidad'] == localidad]\n",
    "    for trimester in trimesterList:\n",
    "        df_by_period = df_by_localidad.loc[df_by_localidad['trimester'] == trimester]\n",
    "        meanPredictability = df_by_period.loc[:,\"predictability\"].mean()\n",
    "        currentVariance = df_by_period.loc[:,\"predictability\"].var()\n",
    "        if flagF==True:\n",
    "            flagF = False\n",
    "            varValues = np.array([localidad,trimester,meanPredictability,currentVariance]);\n",
    "        else:\n",
    "            varValues = np.vstack((varValues, [localidad,trimester,meanPredictability,currentVariance]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_variance_prediction = pd.DataFrame(varValues, columns=['localidad','period','p','p_variance'])\n",
    "periodCategories = list(df_variance_prediction['period'].unique())\n",
    "table_predictability_variance(df_variance_prediction,lenWindow,localidadesList,periodCategories,expName,Levels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localidades, bimester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Levels=[3]\n",
    "lenWindow = 7\n",
    "levelCategories = list(map(lambda x: str(x), Levels))\n",
    "localidadesList = list(df_by_date.LOCALIDAD.unique())\n",
    "localidadesList.remove('SIN LOCALIZACION')\n",
    "localidadesList.remove('SUMAPAZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(df_input['ANIO'].unique())\n",
    "years.remove(2019)\n",
    "bimesters = [1, 2, 3, 4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predValues_array = []\n",
    "for year in years:\n",
    "    for bimester in bimesters:\n",
    "        period_list = build_bimester_list(str(year),bimester)\n",
    "        print(period_list)\n",
    "        df_by_period=df_by_date[df_by_date.PERIODO_TS.isin(period_list)]\n",
    "\n",
    "        min_date_on_period = df_by_period.reset_index().date.min()\n",
    "        max_date_on_period = df_by_period.reset_index().date.max()\n",
    "\n",
    "        expName = 'aggressiveBehavior_localidad_by_bimester_full_dataset'\n",
    "        periodName = str(year)+'-'+str(bimester)\n",
    "        predValues = predictability_experiment_localidades(df_by_period,min_date_on_period,max_date_on_period,lenWindow,localidadesList,Levels,expName,periodName)\n",
    "        predValues_array = predValues_array + list(predValues)\n",
    "    \n",
    "df_prediction = pd.DataFrame(predValues_array, columns=['experiment_name','period','localidad','lenWindow','crime_level','predictability','contingency','constancy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction.loc[df_prediction.period.str.contains(\"-1\"), 'bimester'] = 'I'\n",
    "df_prediction.loc[df_prediction.period.str.contains(\"-2\"), 'bimester'] = 'II'\n",
    "df_prediction.loc[df_prediction.period.str.contains(\"-3\"), 'bimester'] = 'III'\n",
    "df_prediction.loc[df_prediction.period.str.contains(\"-4\"), 'bimester'] = 'IV'\n",
    "df_prediction.loc[df_prediction.period.str.contains(\"-5\"), 'bimester'] = 'V'\n",
    "df_prediction.loc[df_prediction.period.str.contains(\"-6\"), 'bimester'] = 'VI'\n",
    "df_prediction[\"year\"] = df_prediction.period.str.extract(r'(\\d{4})')\n",
    "df_prediction['predictability']=pd.to_numeric(df_prediction['predictability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bimesterList = df_prediction.bimester.unique()\n",
    "flagF = True\n",
    "for localidad in localidadesList:\n",
    "    df_by_localidad = df_prediction.loc[df_prediction['localidad'] == localidad]\n",
    "    for bimester in bimesterList:\n",
    "        df_by_period = df_by_localidad.loc[df_by_localidad['bimester'] == bimester]\n",
    "        meanPredictability = df_by_period.loc[:,\"predictability\"].mean()\n",
    "        currentVariance = df_by_period.loc[:,\"predictability\"].var()\n",
    "        if flagF==True:\n",
    "            flagF = False\n",
    "            varValues = np.array([localidad,bimester,meanPredictability,currentVariance]);\n",
    "        else:\n",
    "            varValues = np.vstack((varValues, [localidad,bimester,meanPredictability,currentVariance]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_variance_prediction = pd.DataFrame(varValues, columns=['localidad','period','p','p_variance'])\n",
    "periodCategories = list(df_variance_prediction['period'].unique())\n",
    "table_predictability_variance(df_variance_prediction,lenWindow,localidadesList,periodCategories,expName,Levels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localidades, months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Levels=[3]\n",
    "lenWindow = 7\n",
    "levelCategories = list(map(lambda x: str(x), Levels))\n",
    "localidadesList = list(df_by_date.LOCALIDAD.unique())\n",
    "localidadesList.remove('SIN LOCALIZACION')\n",
    "localidadesList.remove('SUMAPAZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(df_input['ANIO'].unique())\n",
    "years.remove(2019)\n",
    "all_months = df_by_date.PERIODO_TS.unique()\n",
    "all_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile(r'(2019)')\n",
    "months = [m for m in all_months if not regex.match(m)]\n",
    "print(months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: change size table\n",
    "#fig.set_size_inches(14, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predValues_array = []\n",
    "for month in months:\n",
    "    period_list = []\n",
    "    period_list.append(month)\n",
    "    print(period_list)\n",
    "    df_by_period=df_by_date[df_by_date.PERIODO_TS.isin(period_list)]\n",
    "\n",
    "    min_date_on_period = df_by_period.reset_index().date.min()\n",
    "    max_date_on_period = df_by_period.reset_index().date.max()\n",
    "\n",
    "    expName = 'aggressiveBehavior_localidad_by_month_full_dataset'\n",
    "    periodName = str(month)\n",
    "    predValues = predictability_experiment_localidades(df_by_period,min_date_on_period,max_date_on_period,lenWindow,localidadesList,Levels,expName,periodName)\n",
    "    predValues_array = predValues_array + list(predValues)\n",
    "    \n",
    "df_prediction = pd.DataFrame(predValues_array, columns=['experiment_name','period','localidad','lenWindow','crime_level','predictability','contingency','constancy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction[\"month\"] = df_prediction.period.str.extract(r'(\\d{2}$)')\n",
    "df_prediction[\"year\"] = df_prediction.period.str.extract(r'(\\d{4})')\n",
    "df_prediction['predictability']=pd.to_numeric(df_prediction['predictability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthList = df_prediction.month.unique()\n",
    "flagF = True\n",
    "for localidad in localidadesList:\n",
    "    df_by_localidad = df_prediction.loc[df_prediction['localidad'] == localidad]\n",
    "    for month in monthList:\n",
    "        df_by_period = df_by_localidad.loc[df_by_localidad['month'] == month]\n",
    "        meanPredictability = df_by_period.loc[:,\"predictability\"].mean()\n",
    "        currentVariance = df_by_period.loc[:,\"predictability\"].var()\n",
    "        if flagF==True:\n",
    "            flagF = False\n",
    "            varValues = np.array([localidad,month,meanPredictability,currentVariance]);\n",
    "        else:\n",
    "            varValues = np.vstack((varValues, [localidad,month,meanPredictability,currentVariance]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_variance_prediction = pd.DataFrame(varValues, columns=['localidad','period','p','p_variance'])\n",
    "df_variance_prediction['p']=pd.to_numeric(df_variance_prediction['p'])\n",
    "df_variance_prediction['p_variance']=pd.to_numeric(df_variance_prediction['p_variance'])\n",
    "periodCategories = list(df_variance_prediction['period'].unique())\n",
    "table_predictability_variance(df_variance_prediction,lenWindow,localidadesList,periodCategories,expName,Levels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_variance_prediction.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flagF = True\n",
    "for localidad in localidadesList:\n",
    "    df_by_localidad = df_variance_prediction.loc[df_variance_prediction['localidad'] == localidad]\n",
    "    totalVariance = df_by_localidad.loc[:,\"p_variance\"].sum()\n",
    "    if flagF==True:\n",
    "        flagF = False\n",
    "        varianceArray = np.array([localidad,totalVariance]);\n",
    "    else:\n",
    "        varianceArray = np.vstack((varianceArray, [localidad,totalVariance]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varianceArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Localidades with higher predictability values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_localidad = df_prediction[df_prediction[\"localidad\"] == \"CIUDAD BOLIVAR\"]\n",
    "fig = px.scatter(df_localidad, x=\"month\", y=\"predictability\",color=\"year\",size=\"predictability\")\n",
    "#fig.update_xaxes(range=[-1, 12])\n",
    "fig.update_yaxes(range=[0, 1.05])\n",
    "fig.update_yaxes(nticks=20)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_localidad = df_prediction[df_prediction[\"localidad\"] == \"BOSA\"]\n",
    "fig = px.scatter(df_localidad, x=\"month\", y=\"predictability\",color=\"year\",size=\"predictability\")\n",
    "#fig.update_xaxes(range=[-1, 12])\n",
    "fig.update_yaxes(range=[0, 1.05])\n",
    "fig.update_yaxes(nticks=20)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Localidades with low predictability values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_localidad = df_prediction[df_prediction[\"localidad\"] == \"TEUSAQUILLO\"]\n",
    "fig = px.scatter(df_localidad, x=\"month\", y=\"predictability\",color=\"year\",size=\"predictability\")\n",
    "#fig.update_xaxes(range=[-1, 12])\n",
    "fig.update_yaxes(range=[0, 1.05])\n",
    "fig.update_yaxes(nticks=20)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_localidad = df_prediction[df_prediction[\"localidad\"] == \"LOS MARTIRES\"]\n",
    "fig = px.scatter(df_localidad, x=\"month\", y=\"predictability\",color=\"year\",size=\"predictability\")\n",
    "#fig.update_xaxes(range=[-1, 12])\n",
    "fig.update_yaxes(range=[0, 1.05])\n",
    "fig.update_yaxes(nticks=20)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Localidades with the lowest variance index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_localidad = df_prediction[df_prediction[\"localidad\"] == \"KENNEDY\"]\n",
    "fig = px.scatter(df_localidad, x=\"month\", y=\"predictability\",color=\"year\",size=\"predictability\")\n",
    "#fig.update_xaxes(range=[-1, 12])\n",
    "fig.update_yaxes(range=[0, 1.05])\n",
    "fig.update_yaxes(nticks=20)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_localidad = df_prediction[df_prediction[\"localidad\"] == \"SAN CRISTOBAL\"]\n",
    "fig = px.scatter(df_localidad, x=\"month\", y=\"predictability\",color=\"year\",size=\"predictability\")\n",
    "#fig.update_xaxes(range=[-1, 12])\n",
    "fig.update_yaxes(range=[0, 1.05])\n",
    "fig.update_yaxes(nticks=20)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Localidades with the highest variance index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_localidad = df_prediction[df_prediction[\"localidad\"] == \"SANTA FE\"]\n",
    "fig = px.scatter(df_localidad, x=\"month\", y=\"predictability\",color=\"year\",size=\"predictability\")\n",
    "#fig.update_xaxes(range=[-1, 12])\n",
    "fig.update_yaxes(range=[0, 1.05])\n",
    "fig.update_yaxes(nticks=20)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_localidad = df_prediction[df_prediction[\"localidad\"] == \"PUENTE ARANDA\"]\n",
    "fig = px.scatter(df_localidad, x=\"month\", y=\"predictability\",color=\"year\",size=\"predictability\")\n",
    "#fig.update_xaxes(range=[-1, 12])\n",
    "fig.update_yaxes(range=[0, 1.05])\n",
    "fig.update_yaxes(nticks=20)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
