{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment description\n",
    "## Hypothesis: \n",
    "H1: Predictability results are not affected by the 'localidad' size.\n",
    "## Method: \n",
    "Use of predictability and complementary measures such as constancy and contingency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-in methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import math\n",
    "from math import pi\n",
    "import geopandas as gpd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_initial_dataset_day(df_by_date,name_day):\n",
    "    df_by_date = df_by_date.reset_index()\n",
    "    df_by_date['day_of_week'] = df_by_date['date'].dt.day_name()\n",
    "    monday_idx = df_by_date.index[df_by_date['day_of_week'] == name_day].tolist()[0]\n",
    "    df_by_date = df_by_date[monday_idx:].set_index('date').drop(['day_of_week'],axis=1)\n",
    "    return df_by_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://plot.ly/python/v3/fft-filters/\n",
    "def low_pass_filter(signal_values, fc =0.04, b =0.08):\n",
    "    N = int(np.ceil((4 / b)))\n",
    "    if not N % 2: N += 1\n",
    "    n = np.arange(N)\n",
    "\n",
    "    sinc_func = np.sinc(2 * fc * (n - (N - 1) / 2.))\n",
    "    window = 0.42 - 0.5 * np.cos(2 * np.pi * n / (N - 1)) + 0.08 * np.cos(4 * np.pi * n / (N - 1))\n",
    "    sinc_func = sinc_func * window\n",
    "    sinc_func = sinc_func / np.sum(sinc_func)\n",
    "\n",
    "    s = signal_values\n",
    "    s = s - np.nanmean(s)\n",
    "    filtered_signal = np.convolve(s, sinc_func)\n",
    "    return filtered_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods for slicing windows\n",
    "def im2patches(im,n):\n",
    "    patches = [];\n",
    "    for i in range(len(im)-n):\n",
    "        patch = im[i:(i+n-1)]        \n",
    "        patch = patch - np.nanmean(patch);\n",
    "        if(np.linalg.norm(patch)>0):\n",
    "            patch = patch/np.linalg.norm(patch);\n",
    "        if i==0:\n",
    "            patches = patch;\n",
    "        else:\n",
    "            patches = np.vstack((patches,patch))\n",
    "    return patches;\n",
    "\n",
    "\n",
    "def writeEmbeding(timeSeries,lenWindow,samplePath, scenarioName):\n",
    "    slicingWindows = im2patches(timeSeries,lenWindow);\n",
    "    workingPath = '/Users/anamaria/Desktop/dev/security_project/periodicity_experiments/predictability/slicing/'\n",
    "    prevStation = str(samplePath);\n",
    "    with open(workingPath+'slicingWindows'+\"_\"+str(prevStation)+\"_\"+str(scenarioName)+\"_\"+str(lenWindow)+'_.pickle', 'wb') as f:\n",
    "        lv = slicingWindows.tolist();                        \n",
    "        pickle.dump(lv, f, protocol=2)\n",
    "\n",
    "    workingPath = '/Users/anamaria/Desktop/dev/security_project/periodicity_experiments/predictability/timeSeries/'    \n",
    "    with open(workingPath+'timeSeries'+\"_\"+str(prevStation)+\"_\"+str(scenarioName)+\"_\"+str(lenWindow)+'_.pickle', 'wb') as f:\n",
    "        lv = timeSeries.tolist();                        \n",
    "        pickle.dump(lv, f, protocol=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Methods for predictability\n",
    "def getBarcode(samplePath,lenWindow,scenarioName):\n",
    "    workingPath = '/Users/anamaria/Desktop/dev/security_project/periodicity_experiments/predictability/'\n",
    "    barcode = [];\n",
    "\n",
    "    with open(workingPath+'timeSeries/'+'timeSeries_'+samplePath+\"_\"+str(scenarioName)+'_'+str(lenWindow)+'_'+'.pickle', 'rb') as f:\n",
    "            timeSeries = pickle.load(f);            \n",
    "    return (barcode,timeSeries);\n",
    "\n",
    "def computeBarcodeEntropy(barsLenB0):\n",
    "    barlen = np.array(barsLenB0);\n",
    "    barlen = barlen/barlen.sum();\n",
    "    hbc = 0;\n",
    "    for i in range(barlen.shape[0]):\n",
    "        if barlen[i]!=0:\n",
    "            hbc = hbc-(barlen[i])*np.log(barlen[i]);\n",
    "    return hbc;\n",
    "\n",
    "\n",
    "def computeGeneralPredictability(timeSeries,binsData,lenWindow):\n",
    "    # Colwell, R. K. (1974). Predictability, constancy, and contingency of periodic phenomena. Ecology, 55(5), 1148-1153.\n",
    "    # Normalize the caudal values\n",
    "    nLevels = binsData.shape[0]-1;\n",
    "    matStations = np.array(timeSeries).reshape((np.array(timeSeries).shape[0]//lenWindow,lenWindow))    \n",
    "\n",
    "    grandMean = np.mean(np.mean(matStations));\n",
    "    #matStations = matStations / grandMean;\n",
    "    N = np.zeros((nLevels,lenWindow));\n",
    "    for i in range(1,matStations.shape[1]): \n",
    "        # Computes histograms per columns\n",
    "        hist, bin_edges = np.histogram(matStations[:,i],bins = binsData);\n",
    "        N[:,i] = hist;\n",
    "    X = np.sum(N, axis=0);\n",
    "    Y = np.sum(N, axis=1);\n",
    "    Z = np.sum(Y);\n",
    "    hx = 0;\n",
    "    hy = 0;\n",
    "    hxy = 0;\n",
    "    for j in range(X.shape[0]):\n",
    "        if X[j]!=0:\n",
    "            hx = hx-(X[j]/Z)*np.log(X[j]/Z);\n",
    "            \n",
    "    for i in range(Y.shape[0]):\n",
    "        if Y[i]!=0:\n",
    "            hy = hy-(Y[i]/Z)*np.log(Y[i]/Z);\n",
    "            \n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(X.shape[0]):\n",
    "            if N[i,j]!=0:\n",
    "                hxy = hxy-((N[i,j]/Z)*np.log(N[i,j]/Z));    \n",
    "    \n",
    "    # predictability\n",
    "    p = 1 - (hxy - hx)/np.log(N.shape[0]);\n",
    "    # constancy\n",
    "    c = 1 - hy/np.log(N.shape[0]);\n",
    "    # Returns constancy and contingency\n",
    "    return (c,p-c,p);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localidadSize = {'ANTONIO NARIÃ‘O':109199,\n",
    "                 'BARRIOS UNIDOS':270280,\n",
    "                 'BOSA':753496,\n",
    "                 'CANDELARIA':22243,\n",
    "                 'CHAPINERO':126192,\n",
    "                 'CIUDAD BOLIVAR':748012,\n",
    "                 'ENGATIVA':883319,\n",
    "                 'FONTIBON':424038,\n",
    "                 'KENNEDY':1230539,\n",
    "                 'LOS MARTIRES':93248,\n",
    "                 'PUENTE ARANDA':218555,\n",
    "                 'RAFAEL URIBE URIBE':348023,\n",
    "                 'SAN CRISTOBAL':392220,\n",
    "                 'SANTA FE':93857,\n",
    "                 'SUBA':1315509,\n",
    "                 'TEUSAQUILLO':140135,\n",
    "                 'TUNJUELITO':186383,\n",
    "                 'USAQUEN':475275,\n",
    "                 'USME':342940}\n",
    "\n",
    "def predictability_experiment(df_by_date,lenWindow,localidadesList,Levels,lT):\n",
    "    #write embeding\n",
    "    for localidad in localidadesList:\n",
    "        df_by_localidad = df_by_date[df_by_date['LOCALIDAD'] == localidad]\n",
    "        print(localidad)\n",
    "        \n",
    "        #Normalize events considering localidad size\n",
    "        df_by_localidad['total_eventos'] = df_by_localidad['total_eventos']/localidadSize[localidad]\n",
    "        print(pd.Series(df_by_localidad['total_eventos']).values[0:5])\n",
    "        \n",
    "        #Make sure dataset starts on Monday for the experiment\n",
    "        df_by_localidad = set_initial_dataset_day(df_by_localidad,'Monday')\n",
    "        \n",
    "        #Make sure dataset include consecutive dates in period\n",
    "        idx = pd.date_range(min(df_by_localidad.reset_index().date), max(df_by_localidad.reset_index().date))\n",
    "        df_by_localidad = df_by_localidad.reindex(idx, fill_value=0)\n",
    "        \n",
    "        df_localidad_values = pd.Series(df_by_localidad['total_eventos']).values\n",
    "        df_localidad_values = df_localidad_values[0:lT]\n",
    "        print(df_localidad_values[0:5])\n",
    "        print('=============')\n",
    "        writeEmbeding(df_localidad_values,lenWindow,'aggressiveBehavior',localidad)\n",
    "    \n",
    "    #find predictability, constancy and contingency\n",
    "    workingPath = '/Users/anamaria/Desktop/dev/security_project/periodicity_experiments/predictability/';\n",
    "\n",
    "    flagF = True;\n",
    "    for localidad in localidadesList:        \n",
    "        for nLevels in Levels:\n",
    "            for expName in ['aggressiveBehavior']:\n",
    "            #for expName in ['aggressiveBehavior','random']:\n",
    "                (barcode,timeSeries) = getBarcode(expName,lenWindow,localidad);\n",
    "                binsLevels = np.linspace(np.min(timeSeries),np.max(timeSeries),nLevels);\n",
    "                #print(nLevels)\n",
    "                #print(localidad)\n",
    "                c,m,p = computeGeneralPredictability(timeSeries,binsLevels,lenWindow)\n",
    "                \n",
    "                if flagF==True:\n",
    "                    flagF = False\n",
    "                    predValues = np.array([expName,localidad,lenWindow,nLevels,p,m,c]);\n",
    "                else:\n",
    "                    predValues = np.vstack((predValues, [expName,localidad,lenWindow,nLevels,p,m,c]))\n",
    "\n",
    "    return predValues\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_predictability_report(df_agressiveBehavior,lenWindow,localidadesList,levelCategories,name_experiment):\n",
    "    join=df_agressiveBehavior.pivot('localidad','crime_level','predictability')\n",
    "    var1_order = []\n",
    "    var2_order = levelCategories\n",
    "    if len(var2_order) > 0:\n",
    "        join = join.reindex(var2_order, axis=1)\n",
    "    if len(var1_order) > 0:\n",
    "        join = join.reindex(var1_order)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1,sharex=True, sharey=True)\n",
    "    fig.set_size_inches(7, 6)\n",
    "    g=sns.heatmap(join.astype('float'),annot=True,fmt=\".1%\",linewidths=0,cmap=\"Blues\",cbar=False)\n",
    "    g.set_yticklabels(g.get_yticklabels(), rotation = 0)\n",
    "    bottom, top = ax.get_ylim()\n",
    "    ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "    file_path = '/Users/anamaria/Desktop/dev/security_project/periodicity_experiments/predictability/figures/'\n",
    "    plt.savefig(file_path+'table_aggressiveBehavior_localidades'+str(name_experiment)+'_predictability_time_'+str(lenWindow)+'_levels_'+str(levelCategories),dpi=300,bbox_inches = \"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_constancy_report(df_agressiveBehavior,lenWindow,localidadesList,levelCategories,name_experiment):\n",
    "    join=df_agressiveBehavior.pivot('localidad','crime_level','constancy')\n",
    "    var1_order = []\n",
    "    var2_order = levelCategories\n",
    "    if len(var2_order) > 0:\n",
    "        join = join.reindex(var2_order, axis=1)\n",
    "    if len(var1_order) > 0:\n",
    "        join = join.reindex(var1_order)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1,sharex=True, sharey=True)\n",
    "    fig.set_size_inches(7, 6)\n",
    "    g=sns.heatmap(join.astype('float'),annot=True,fmt=\".1%\",linewidths=0,cmap=\"Blues\",cbar=False)\n",
    "    g.set_yticklabels(g.get_yticklabels(), rotation = 0)\n",
    "    bottom, top = ax.get_ylim()\n",
    "    ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "    file_path = '/Users/anamaria/Desktop/dev/security_project/periodicity_experiments/predictability/figures/'\n",
    "    plt.savefig(file_path+'table_aggressiveBehavior_localidades'+str(name_experiment)+'_constancy_time_'+str(lenWindow)+'_levels_'+str(levelCategories),dpi=300,bbox_inches = \"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_localidad(ax,df,col_localidad,col_vals,vmin=None,vmax=None):\n",
    "  loc_geo=\"/Users/anamaria/Desktop/dev/security_project/assets/localidades_polygon.json\"\n",
    "  loc_=gpd.read_file(loc_geo)\n",
    "  loc_=loc_.merge(df,left_on='LocNombre',right_on=col_localidad)\n",
    "  loc_.plot(cmap='viridis',column=col_vals,legend=True,ax=ax,vmin=vmin,vmax=vmax)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_predictability(df_crime, crime_level, lenWindow,name_experiment):\n",
    "    subdata = df_crime[df_crime['crime_level']==crime_level]\n",
    "    subdata = subdata[subdata['lenWindow']==str(lenWindow)]\n",
    "    subdata[\"predictability\"] = pd.to_numeric(subdata[\"predictability\"])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12,12))\n",
    "    map_localidad(ax,subdata,'localidad','predictability')\n",
    "    ax.axis('off')\n",
    "    file_path = '/Users/anamaria/Desktop/dev/security_project/periodicity_experiments/predictability/figures/'\n",
    "    plt.savefig(file_path+'map_aggressiveBehavior_localidades'+str(name_experiment)+'_predictability_time_'+str(lenWindow)+'_levels_'+str(crime_level),dpi=300,bbox_inches = \"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = '/Users/anamaria/Desktop/dev/security_project/datasets/verify_enrich_nuse_29112019.csv'\n",
    "df_input = pd.read_csv(data_location,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input['date']=pd.to_datetime(df_input['FECHA'])\n",
    "df_by_date = pd.DataFrame(df_input.groupby(['date','LOCALIDAD']).size(),columns=[\"total_eventos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_date = df_by_date.reset_index().set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment to validate H1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Levels=[3,5,10]\n",
    "levelCategories = list(map(lambda x: str(x), Levels))\n",
    "localidadesList = list(df_by_date.LOCALIDAD.unique())\n",
    "localidadesList.remove('SIN LOCALIZACION')\n",
    "timeWindows = [7, 14, 28, 84]\n",
    "lT = 756\n",
    "name_experiment = '_normalizadas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lenWindow in timeWindows:\n",
    "    predValues = predictability_experiment(df_by_date,lenWindow,localidadesList,Levels,lT)\n",
    "    df_prediction = pd.DataFrame(predValues, columns=['crime_type', 'localidad','lenWindow','crime_level','predictability','contingency','constancy'])\n",
    "    df_agressiveBehavior = df_prediction[df_prediction['crime_type']=='aggressiveBehavior']\n",
    "    table_predictability_report(df_agressiveBehavior,lenWindow,localidadesList,levelCategories,name_experiment)\n",
    "    crime_level = levelCategories[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
